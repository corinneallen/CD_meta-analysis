---
title: "Co-occurrence patterns of photosymbiont genera in reef-building corals: a global review and meta-analysis"

abstract: "Coral reefs are experiencing unprecedented global declines driven by intensifying marine heatwaves, deoxygenation, and other consequences of climate change. One trait that may enhance coral resilience is their ability to harbour diverse communities of microalgal symbionts (Symbiodiniaceae). Cladocopium and Durusdinium are two common Symbiodiniaceae genera harbouring functionally different traits; however, the extent to which they co-occur within coral hosts has not yet been explored. Here, we conducted a systematic literature review and meta-analysis to assess global patterns of Cladocopium-Durusdinium co-occurrence and co-phylogeny, synthesising data from ~36,000 coral colonies across 378 studies, 98 coral genera, 77 countries and territories, 11 genetic markers, and 13 genetic analysis techniques. Co-occurrence prevalence across these studies was 9.6%, with estimates varying across methodological, biological, spatial, and study variables. Incorporation of more recent high-sensitivity genotyping and intra-colony sampling increased this estimate by up to 7.1-fold, suggesting that Cladocopium-Durusdinium co-occurrence may be more common than previously recognised. We also identified a co-phylogenetic signal between putative Cladocopium and Durusdinium taxa, suggesting that in some cases, these symbionts have co-evolved. Together, these findings contribute to the understanding of eco-evolutionary relationships between symbionts within coral hosts, providing important insight into the adaptive capacity of corals in a changing climate."

author: "Corinne Allen and Matthew Nitschke"
date: "2025-09-30"
output: html_document
---

#Load in libraries
```{r setup, include=FALSE}
knitr::opts_chunk$set(warning = FALSE, message = FALSE) 

#Packages used for data reading/wrangling
library(tidyverse)
library(dplyr)
library(readxl)
library(writexl)
library(janitor)
library(reshape2)
library(vegan)
library(segmented)
#Packages for text mining
library(tm)
library(pdftools)
#Packages used for plotting
library(ggplot2)
library(patchwork)
library(scales)
library(scatterpie)
library(viridis)
library(ggnewscale)
library(ggstance)
#Packages used for spatial analysis
library(sf)
library(sp)
library(rnaturalearth)
library(rnaturalearthdata)
library(geosphere)
library(geodist)
library(ggspatial)
#Packages used for meta-analysis
library(meta)
library(metafor)
library(orchaRd)
#Packages used for phylogeny
library(phyr)
library(ape)
library(ggtree)
library(tidytree)
library(phytools)
library(units)


select <- dplyr::select
rename <- dplyr::rename


```

# Eligible studies
```{r}
#Spreadsheet of remaining studies after duplicate deletion with reasons for exclusion or inclusion (i.e., from abstract screen and full text review)
studies <- read_xlsx("Table_S1.xlsx")%>%
  row_to_names(row_number = 1)
  #mutate(index=as.numeric(index))

#Summary information. NA: did not pass abstract screen; NO: passed, but excluded; YES: passed and extracted
summary <- studies%>%
  group_by(extracted)%>%
  summarise(n=n())

#Reasons for exclusion 
exclusion_reasons <- read_csv("exclusion_reasons.csv")
excluded <- studies%>%
  filter(extracted=="NO")%>%
  left_join(exclusion_reasons)%>%
  group_by(reason_cleaned)%>%
  summarise(count=n())%>%
  mutate(total=sum(count))%>%
  mutate(prop=(count/total)*100)%>%
  mutate_if(is.numeric, round, 0)%>%
  arrange(count)

```

# Term library and article sorting

NOTE: need to obtain PDFs of studies in order to run this chunk of code. Due to licensing we cannot include the PDFs as part of the supplementary, but still show the process. Essentially, a term library was used to sort articles based on 1) number of terms from the term library that appear in that article and 2) the frequency of terms normalised to that article's word count. This is how the database is ordered (which can be seen when it is loaded in the next chunk of code).

```{r}
#### Creating the corpus ####
files <- list.files(pattern = "*.pdf")
corp <- Corpus(URISource(files),
               readerControl = list(reader = readPDF))

#### Cleaning the corpus ####
toSpace <- content_transformer(function(x, pattern) gsub(pattern, " ", x))

# Hyphen/colon/apostrophe replacements
corp <- tm_map(corp, toSpace, "-")
corp <- tm_map(corp, toSpace, " -")
corp <- tm_map(corp, toSpace, ":")
corp <- tm_map(corp, toSpace, "'")

# Punctuation, lowercasing, stopwords, whitespace
corp <- tm_map(corp, removePunctuation)
corp <- tm_map(corp, content_transformer(tolower))
corp <- tm_map(corp, removeWords, stopwords("english"))
corp <- tm_map(corp, stripWhitespace)

# Custom replacement dictionary
replacements <- c(
  "clade c"        = "cladec",
  "clade d"        = "claded",
  "within colony"  = "withincolony",
  "intra colony"   = "intracolony",
  "co existence"   = "coexist",
  "coexistence"    = "coexist",
  "co habitation"  = "cohabitation",
  "co occurrence"  = "cooccur",
  "cooccurrence"   = "cooccur",
  "co exist"       = "coexist",
  "co occur"       = "cooccur"
  # "symbiodinium"   = "symbio",
  # "symbiodiniaceae"= "symbio"
)

# Apply all replacements in one loop
for (pattern in names(replacements)) {
  corp <- tm_map(
    corp,
    content_transformer(gsub),
    pattern = pattern,
    replacement = replacements[[pattern]]
  )
}

#### Creating document term matrix ####
dtm <- DocumentTermMatrix(corp)

dtm_wordcount <- rowSums(as.matrix(dtm)) %>%
  tibble::enframe(name = "index", value = "word_count")

#### Sorting articles based on term library ####
term_library <- read_csv("Table_S2.csv")
term_list <- term_library%>%pull(term)

#Creating dtm based on term library
dtm_filtered <- DocumentTermMatrix(corp, control=list(dictionary = term_list))

dtm_df <- as.matrix(dtm_filtered) %>%
  as.data.frame() %>%
  rownames_to_column("index")%>%
  left_join(dtm_wordcount)%>%
  pivot_longer(cols = all_of(term_list),names_to = "term",values_to = "index_n")%>%
  mutate(index = str_remove(index, "\\.pdf$"))

#Sorting articles based on 1) number of terms from the term library that appear in that article and 2) the frequency of terms normalised to that article's word count. This is the order of articles in the database.
dtm_count <- dtm_df%>%
  filter(index_n>0)%>%
  group_by(index)%>%
  mutate(term_n=n(),
         term_freq=sum(index_n),
         term_freq_norm=term_freq/word_count)%>%
  arrange(desc(term_n), desc(term_freq_norm))

unique_index <- dtm_count%>%
  mutate(index= sprintf("%04s", index))%>%
  distinct(index,.keep_all = T)%>%
  select(index, term_n, term_freq_norm)

```

# Database
```{r}
#Read in cleaned database.
#NOTE: this database is before the methods staging step (completed next)

db_pre <- read_xlsx("Table_S3_database.xlsx")%>%
  filter(symbionts!="O") #removing samples that are not CD.

  
```

# Staging steps to choose methods and markers where multiple methods or markers were used
```{r}
#Unique markers and methods
markers_n <- db_pre %>%
  distinct(marker) %>%
  filter(!grepl("/|,|and|NA|ND", marker)) %>%
  drop_na()

methods_n <- db_pre %>%
  distinct(method)

#Prepare main dataframe
db_m <- db_pre %>%
  select(row, index, year:lon, quantity:species, time_points, intracolony_samples, symbionts, notes_questions)

#Method and marker ranking
marker_rank <- tibble(marker = c("ITS2", "28S", "cp23S", "psbA ncr", "ITS1", "ITS", "cox1", "cob", "18S", "SNPs", "Actin"),
                      marker_rank = 1:11)

method_rank <- tibble(method = c("qPCR", "ddPCR", "NGS", "454 pyrosequencing", "PacBio", "ONT", "WGS","Cloning and sequencing", "DGGE", "Sanger sequencing", "SSCP", "RFLP", "Genotyping arrays"),
                      method_rank = 1:13)

#Multiple markers and methods per index
multiple_markers <- db_m%>%
  filter(multiple_markers=="Yes")%>%
  distinct(index, marker)%>%
  group_by(index)%>%
  mutate(n_markers=n())%>%
  distinct(index, n_markers)

multiple_methods <- db_m %>%
  filter(multiple_markers == "Yes") %>%
  distinct(index, method) %>%
  group_by(index) %>%
  mutate(n_methods = n()) %>%
  distinct(index, n_methods)

multiple <- multiple_markers %>%
  left_join(multiple_methods, by = "index")

#Same method, different marker
marker_diff_list <- multiple%>%
  filter(c(n_methods==1 & n_markers>1))%>%pull(index)

#Same marker, different method
method_diff_list <- multiple%>%
  filter(c(n_methods>1))%>%pull(index)

mm_comparison <- db_m%>%
  filter(multiple_markers=="Yes")%>%
  group_by(index, method, marker)%>%
  mutate(n_colonies=sum(quantity))%>%
  group_by(index, method, marker, symbionts)%>%
  mutate(n_symbionts=sum(quantity))%>%
  distinct(index, method, marker, symbionts, n_colonies, n_symbionts)%>%
  pivot_wider(names_from = symbionts, values_from = n_symbionts, values_fill = 0)%>%
  ungroup()

#### Selection logic ####
mm_diff <- mm %>%
  group_by(index) %>%
  mutate(
    n_colonies_check = ifelse(n_distinct(n_colonies) == 1, "same n_colonies", "different n_colonies"),
    outcome_check = ifelse(all(apply(across(c(C, CD, D)), 2, function(col) n_distinct(col, na.rm = TRUE)) <= 1), "same_outcome", "different_outcome")
  ) %>%
  ungroup() %>%
  left_join(method_rank, by = "method") %>%
  left_join(marker_rank, by = "marker") %>%
  group_by(index) %>%
  mutate(
    priority_method = method %in% c("qPCR", "NGS"),
    selected_method = case_when(
      #Step 1: If any priority method (i.e., NGS or qPCR) exists, only those are selected
      any(priority_method) ~ priority_method, 
      #Step 2: Same number of colonies, same outcome → choose method with best marker rank
      n_colonies_check == "same n_colonies" & outcome_check == "same_outcome" ~ method_rank == min(method_rank, na.rm = TRUE),
      # Step 3: Same number of colonies, different outcome → choose row with highest CD
      n_colonies_check == "same n_colonies" & outcome_check == "different_outcome" ~ CD == max(CD, na.rm = TRUE),
      #Step 4: Different number of colonies and different outcomes → choose highest n_colonies
      #Except if qPCR or NGS used, which already handled by step 1
      n_colonies_check == "different n_colonies" & outcome_check == "different_outcome" ~ n_colonies == max(n_colonies, na.rm = TRUE),
      TRUE ~ FALSE
    )
  ) %>%
  # Resolve multiple TRUEs
  group_by(index) %>%
  mutate(
    true_count = sum(selected_method, na.rm = TRUE),
    #If multiple TRUE for each index, select rows with max CD
    max_CD = ifelse(true_count > 1, max(CD[selected_method], na.rm = TRUE), NA_real_),
    #Among rows with max CD, choose best marker rank
    min_rank_true = ifelse(true_count > 1, min(marker_rank[selected_method & CD == max_CD], na.rm = TRUE), NA_real_),
    #Keep only rows that satisfy both conditions
    selected_method = ifelse(true_count > 1, selected_method & CD == max_CD & marker_rank == min_rank_true, selected_method)
  ) %>%
  ungroup()%>%
  group_by(index) %>%
  mutate(
    n_method = n_distinct(method),
    n_marker = n_distinct(marker)
  )%>%
  select(index:marker, n_method, n_marker, n_colonies:min_rank_true)
#write_csv("Table_S4.csv")

#Gathering which will be removed from the database
mm_removals <- mm_diff%>%
  ungroup()%>%
  select(index, method, marker, selected_method)%>%
   mutate(index= sprintf("%04s", index))%>%
  mutate(selected_method=case_when((index=="0523" & method=="DGGE") ~ FALSE,
                                   TRUE ~ selected_method))%>%
  filter(selected_method=="FALSE")%>%
  mutate(multiple_markers="Yes")

```

#Cleaned database
```{r}
#Removing duplicate methods/markers used on the same colonies as above
db <- db_pre%>%
  left_join(mm_removals)%>%
  filter(is.na(selected_method))%>%
  mutate(provision = na_if(provision, "ND"))%>%
  mutate(reproduction = na_if(reproduction, "ND"))%>%
  mutate(morpho = na_if(morpho, "ND"))

```

# PART 1: SYSTEMATIC REVIEW
## Study characteristics
```{r}
#### Summary information ####
summary_counts <- db %>%
  summarise(n_index = n_distinct(index),
            n_genera = n_distinct(genus),
            n_country = n_distinct(country),
            n_colonies = sum(quantity, na.rm = TRUE))

#### Study variables ####
study_variables <- db%>%
  select(index, study_factor) %>%
  separate_rows(study_factor, sep = ", ") %>%
  distinct() %>%
  mutate(study_factor = tolower(study_factor)) %>%
  count(study_factor, sort = TRUE)

#### Response variables ####
response_variables <- db%>%
  select(index, response) %>%
  separate_rows(response, sep = ", ") %>%
  distinct() %>%
  mutate(response = tolower(response)) %>%
  count(response, sort = TRUE)

#### Sample sizes ####
sample_sizes <- db%>%
  group_by(index)%>%
  summarise(sample_size=sum(quantity))%>%
  arrange(desc(sample_size))

#### Study type ####
study_type <- db%>%
  distinct(index, type)%>%
  count(type)%>%
  mutate(prop = round(n / sum(n), 2))

#### Intracolony sampling ####
intracolony <- db%>%
  select(index, time_points, intracolony_samples)%>%
  group_by(index) %>%
  summarise(space = any(time_points == 1 & intracolony_samples > 1), # "space" = only one time point but multiple intracolony samples
            time = any(time_points > 1 & intracolony_samples == 1), # "time" = multiple time points but only one intracolony sample at each time point
            space_time = any(time_points > 1 & intracolony_samples > 1), # "space_time" = multiple time points AND multiple intracolony samples
            .groups = "drop")%>%
  mutate(intracolony = case_when(space_time ~ "space_time", # there were some instances where space_time and space may be true if some colonies had multiple time points and some didn't. In this instance, it is classified under space_time.
                                 space & time ~ "space_time",
                                 space ~ "space",
                                 time ~ "time",
                                 TRUE ~ "none")) %>%
  count(intracolony)

```

## Methods and markers - before staging steps 
```{r}
##METHODS
method_articles <- db_pre%>%
  distinct(index, method)%>%
  group_by(method)%>%
  summarise(n=n())%>%
  mutate(total=378)%>%
  mutate(prop=n/total)

method_corals <- db_pre%>%
  select(index,method, quantity)%>%
  drop_na()%>%
  group_by(method)%>%
  summarise(n=sum(quantity))%>%
  mutate(total=sum(n))%>%
  mutate(prop=n/total)

method_year_articles <- db_pre%>%drop_na(year)%>%
  distinct(index, year, method)%>%
  mutate(year=as.numeric(unlist(year)))%>%
  group_by(year, method)%>%
  summarise(n=n())


##MARKERS
marker_articles <- db_pre%>%
  distinct(index, marker)%>%
  group_by(marker)%>%
  summarise(n=n())%>%
  mutate(total=378)%>%
  mutate(prop=n/total)

marker_corals <- db_pre%>%
  select(index,marker, quantity)%>%
  drop_na()%>%
  group_by(marker)%>%
  summarise(n=sum(quantity))%>%
  mutate(total=sum(n))%>%
  mutate(prop=n/total)

marker_year_articles <- db_pre%>%drop_na(year)%>%
  distinct(index, year, marker)%>%
  mutate(year=as.numeric(unlist(year)))%>%
  group_by(year, marker)%>%
  summarise(n=n())%>%
filter(!grepl("/", marker))%>%
  filter(!grepl(",", marker))%>%
  filter(!grepl("and", marker))%>%
  filter(!grepl("NA", marker))%>%
  filter(!grepl("ND", marker))

#### FIGURE S2 ####
marker_supp <- ggplot(marker_year_articles, aes(x=year, y=n, fill=marker))+
  geom_bar(stat = "identity")+
  xlab("Year")+ylab("Number of articles")+
  scale_fill_manual(values=c( "#84A98C", "#2C3E50", "#F1D3B4", "#406F5F", "#B67F5A", "#A9D0D0", "#5D8C8E", "#E63946", "#F4A261","#8E6C88", "#E9C46A"))+
  theme_classic()

method_supp <- ggplot(method_year_articles, aes(x=year, y=n, fill=method))+
  geom_bar(stat = "identity")+
  xlab("Year")+ylab("Number of articles")+
  scale_fill_manual(values=c("#1C1C1C", "#D96F3F", "#84A98C", "#2C3E50", "#F1D3B4", "#406F5F", "#B67F5A", "#A9D0D0", "#5D8C8E", "#E63946", "#F4A261","#8E6C88", "#E9C46A"))+
  theme_classic()

fig_s2 <- marker_supp / method_supp
ggsave("fig_s2.svg", fig_s1, height=8, width=12)

```

## Methods and markers - after staging steps 
```{r}
##METHODS
method_articles <- db%>%
  distinct(index, method)%>%
  group_by(method)%>%
  summarise(n=n())%>%
  mutate(total=378)%>%
  mutate(prop=n/total)

method_corals <- db%>%
  select(index,method, quantity)%>%
  drop_na()%>%
  group_by(method)%>%
  summarise(n=sum(quantity))%>%
  mutate(total=sum(n))%>%
  mutate(prop=n/total)

##MARKERS
marker_articles <- db%>%
  distinct(index, marker)%>%
  group_by(marker)%>%
  summarise(n=n())%>%
  mutate(total=378)%>%
  mutate(prop=n/total)

marker_corals <- db%>%
  select(index,marker, quantity)%>%
  drop_na()%>%
  group_by(marker)%>%
  summarise(n=sum(quantity))%>%
  mutate(total=sum(n))%>%
  mutate(prop=n/total)

```

## Temporal trends in articles
```{r}
temporal_articles <- studies%>%
 # filter(screen=="passed" | screen=="symportal")%>% 
  filter(screen=="passed")%>% #only interested in initial search since symportal will include some from 2023 which skews it
  mutate(year=as.numeric(year))%>%
  group_by(year, extracted)%>%summarise(n=n())%>%
  ungroup()%>%group_by(year)%>%mutate(total=sum(n))

# Checking to see if there is a relationship between year and number of articles published. Exponential model had lower AIC (54) than liner model (214).
exp_eligible <- lm(log(total) ~ year, data = temporal_articles%>%distinct(year, total)%>%drop_na(year))
summary(exp_eligible)$r.squared
AIC(exp_eligible)

# Checking to see if there is a relationship between year and number of articles included. Exponential model had lower AIC (17) than liner model (124).
exp_included <- lm(log(n) ~ year, data = temporal_articles%>%filter(extracted=="YES"))
summary(exp_included)$r.squared
AIC(exp_included)

# Coral colonies sampled per year. NOTE: this removes samples where no year was given
temporal_colonies <- db%>%
  select(row, index, genus, species, quantity, time_points, intracolony_samples, sampling_year)%>%
  mutate(across(c(quantity, time_points, intracolony_samples), as.numeric))%>%
  drop_na()%>%
  mutate(total_samples = quantity * intracolony_samples)%>%
  mutate(sampling_year = str_split(sampling_year, ";\\s*"))%>%
  unnest(sampling_year) %>%
  mutate(year = as.numeric(str_extract(sampling_year, "\\d{4}")))%>%
  distinct(row, index, genus, species, quantity, time_points, intracolony_samples, year)%>%
  group_by(year) %>%
  summarise(sum = sum(quantity), .groups = "drop") %>% drop_na(year)%>%
  mutate(total_sum = sum(sum))

```

## Spatial trends in articles (country)
```{r}
# Number of articles conducting sampling in each country
spatial_articles <- db%>%
  distinct(index, country)%>%
  group_by(country)%>%
  summarise(n_articles=n(), .groups = "drop")

# Number of colonies sampled in each country
spatial_colonies <- db%>%
  select(country, quantity)%>%
  drop_na(quantity)%>%
  group_by(country)%>%
  summarise(sum=sum(quantity))

```

##FIGURE 2
Spatial and temporal trends of included articles.
```{r}
figure_2a <- ggplot()+
  geom_bar(data=temporal_articles, aes(x=year, y=n, fill=extracted), stat="identity") +
  geom_line(data=temporal_colonies, aes(x=year, y=sum/100), color=  "#a39193")+
  geom_point(data=temporal_colonies, aes(x=year, y=sum/100), color= "#a39193")+
   xlab("Year")+scale_y_continuous(name="Number of articles", sec.axis = sec_axis(~. *100, name="Number of corals sampled"))+
  scale_fill_manual(values=c("lightgray",  "#d1ce9d" ), labels=c("Excluded from database", "Included in database"), name="Category")+
  theme_classic()+
  theme(axis.title.y = element_text(size = 9, face="bold"),
         axis.title.x = element_text(size = 9, face="bold"),
         axis.text.y = element_text(size = 8),
         axis.text.x = element_text(size = 8),
         legend.position="top",
         aspect.ratio = 1/6)

figure_2b <- ggplot()+
  geom_bar(data=spatial_articles, aes(x=reorder(country, n_articles),y=n_articles), fill=   "#d1ce9d" , stat="identity")+
  geom_point(data=spatial_colonies, aes(x = reorder(country, sum), y=sum/100), color=  "#a39193")+
  geom_line(data=spatial_colonies, aes(x = reorder(country, sum), y=sum/100, group=1), color=  "#a39193")+
  ylim(0,80)+
  xlab("Country or territory")+scale_y_continuous(name="Number of articles", sec.axis = sec_axis(~. *100, name="Number of corals sampled"))+
  theme_classic()+
  theme(axis.title.y = element_text(size = 9, face="bold"),
         axis.title.x = element_text(size = 9, face="bold"),
         axis.text.y = element_text(size = 8),
         axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1, size=8),
         legend.position="top",
         aspect.ratio = 1/6)

figure_2 <- figure_2a/figure_2b + plot_annotation(tag_levels = "A")
ggsave("figure_2.svg",figure_2, width = 12, height = 8)

```

## FIGURE 3
```{r}
#### Symbiont summary ####
# Number of colonies sampled that harbor C, D, or both C and D.
symbiont_summary <- db%>%
  filter(symbionts != "O", !is.na(quantity), quantity > 0) %>%
  group_by(symbionts, symbionts_name) %>%
  summarise(n = sum(quantity), .groups = "drop") %>%
  mutate(total = sum(n),
         prop  = n / total)

figure_3a <-ggplot(symbiont_summary, aes(x=reorder(symbionts, -n), y=n, fill=symbionts_name))+
  geom_bar(stat="identity")+
  xlab("Symbiont presence")+ylab("Number of colonies")+
  scale_fill_manual(values = c("#f6e0b5", "#66545e", "#ce796b"), name="Symbiont presence")+
  theme_classic()+
  theme(legend.position = "none",  aspect.ratio = 1.5)

#### Global map ####
# Spatial distribution of colonies sampled and the symbionts they harbor 
coords_cleaned <- db%>%
  mutate(lat=as.numeric(lat),
         lon=as.numeric(lon))%>%
  filter(between(lon, -180, 180),
         between(lat, -90, 90))

y <- coords_cleaned$lat
x <- coords_cleaned$lon

# Convert data to a SpatialPointsDataFrame object
xy <- SpatialPointsDataFrame(
      matrix(c(x,y), ncol=2), data.frame(ID=seq(1:length(x))),
      proj4string=CRS("+proj=longlat +ellps=WGS84 +datum=WGS84"))

# Use the distm function to generate a geodesic distance matrix in meters
mdist <- distm(xy)

# Cluster all points using a hierarchical clustering approach
hc <- hclust(as.dist(mdist), method="complete") 

# Define the distance threshold (100km)
d=100000 

# Assign cluster IDs to points based on cutoff "d" and add them to the SpatialPointsDataFrame
xy$clust <- cutree(hc, h=d) 

# Extract one representative point per cluster
clust_distinct <- as.data.frame(xy)%>%
  rename(lon = coords.x1, lat = coords.x2)%>%
  distinct(clust, .keep_all=T)

# Summarise symbiont counts per cluster
xy_df <- as.data.frame(xy)%>%
  rename(lon = coords.x1, lat = coords.x2)%>%
  left_join(coords_cleaned, by = c("lon", "lat"))%>%
  distinct(row, .keep_all = TRUE)%>%
  filter(symbionts!="O")%>%
  group_by(clust, symbionts)%>%
  summarise(n = sum(quantity), .groups = "drop")%>%
  pivot_wider(names_from = symbionts, values_from = n, values_fill = 0) %>%
  left_join(clust_distinct, by = "clust") %>%
  mutate(n_total = C + D + CD, #total number of samples in cluster
         bin = case_when(n_total < 100 ~ 1, 
                    n_total < 500 ~ 4,
                    n_total < 1000 ~ 6,
                    n_total < 2000 ~ 8,
                    n_total >= 2000 ~ 10)) #bin cluster size for plotting
  
# Obtain sf object of world countries
world <- ne_countries(scale = "medium", returnclass = "sf") 

figure_3b <- ggplot(data = world) +
  geom_sf(fill="whitesmoke")+
  geom_scatterpie(data = xy_df,
                  aes(x=lon, y=lat, r=sqrt(bin)*2),
                  alpha=0.8,
                  cols = c("C", "D", "CD"), color=NA)+
  # Explicitly add a size legend by using geom_point()
  geom_point(data = xy_df, 
             aes(x = lon, y = lat, size = sqrt(bin)*2), 
             alpha = 0.0,   # Make the points invisible, but the size legend will still appear
             show.legend = TRUE) + 
  scale_fill_manual(values = c("#f6e0b5", "#ce796b", "#66545e"), name="Symbiont category")+
  scale_size_continuous(limits = c(1, 3000),
                         breaks = c(100, 500, 1000, 2000, 2500),
                         labels= c("<100", "100-500", "500-1000", "1000-2000", ">2000"),
                         name = "Number of samples",
                         range=c(3,10))+
  xlab("")+ylab("")+
  coord_sf(expand = FALSE)+
  theme_classic()+
  theme(legend.position = "bottom")


figure_3<-(figure_3a | figure_3b) + plot_annotation(tag_levels = "A") +  plot_layout(widths = c(1,3), heights=c(1,1), guides = "collect") & theme(legend.position = 'bottom')

ggsave("figure_3.svg",figure_3, width = 12, height = 8)

```

# PART 2: META-ANALYSIS OF PREVALENCE

This section calculates the overall prevalence of co-occurrence across all studies. We first summarize the total number of colonies sampled (`ni`) and the number with co-occurrence (`xi`) per study and calculate the proportion (`prop`). We then perform a random-effects meta-analysis using a logit transformation and determined the variance explained by heterogeneity (`I²`). Orchards plots are used to visualise the prevalence estimate of each study (i.e., bubble) in relation the the pooled estimate (dashed line).

## Overall - m1
```{r}
# OVERALL
data_m1 <- db%>%
  drop_na(quantity)%>%
  group_by(index,symbionts)%>%
  summarise(number=sum(quantity))%>%
  pivot_wider(names_from = symbionts, values_from = number, values_fill=0)%>% 
  mutate(ni=C+D+CD, # total number of colonies per index
         xi=CD, # number of colonies with co-occurrence
         prop=xi/ni, # prevalence of co-occurrence per index
         se = sqrt(prop * (1 -prop) / ni)) #standard error of proportion

m1_in <- escalc(xi=xi, ni=ni, data=data_m1, measure = "PLO") # calculate logit-transformed effect sizes
m1<-rma.mv(yi, vi, random=~1|index, data=m1_in) # fit random-effects meta-analysis model
pred_m1 <- predict(m1, transf = transf.ilogit) # predict back on original scale (prevalence)

# Calculate I² (heterogeneity)
Q <- summary(m1)$QE # cochran's Q
df <- length(m1$yi) - length(m1$coef) # degrees of freedom
I2 <- ((Q - df) / Q) * 100 # proportion of variance due to heterogeneity
print(I2)

m1_plot <- orchard_plot(m1,xlab = "Prevalence", group="index",angle = 45,g = FALSE, 
                    legend.pos = "none",  transfm="invlogit", weights="N", twig.size = FALSE)+
  geom_hline(yintercept = 0.096, linetype = "dashed", color = "black", size = 0.6)  +
  scale_fill_manual(values = "lightgray")+scale_color_manual(values = "gray")+
  theme_classic()+
  ggtitle("Overall pooled estimate") +
  theme(plot.title = element_text(face = "bold", size = 10),
        legend.position="none")

```

## Functions for subgroup models

Due to high heterogeneity, we perform meta-analyses looking at different methodological (m2-m3), biological (m4-m7), spatial (m8-m10), and study-level (m11-m13) variables. For each moderator, we calculated logit-transformed effect sizes, fitted random-effects models with study as a random effect, quantified heterogeneity (I²) and variance explained (R²), and visualized subgroup estimates using orchard plots. Custom functions were created to streamline the analysis and then applied to each moderator.

```{r}

#### Function to prep data ####
prep_data <- function(df, moderator = "method") {
  df %>%
    summarise(number = sum(quantity), .groups = "drop_last") %>%
    pivot_wider(names_from = symbionts, values_from = number, values_fill = 0) %>%
    mutate(ni   = C + D + CD, # total colonies
           xi   = CD, # colonies with co-occurrence
           prop = xi / ni, # prevalence/proportion of colonies with co-occurrence
           se   = sqrt(prop * (1 - prop) / ni), # standard error
      !!moderator := factor(.data[[moderator]])) %>%
    drop_na()
}

#### Function to fit model ####
fit_model <- function(data, moderator) {
  data_es <- escalc(xi = xi, ni = ni, data = data, measure = "PLO") # calculate logit-transformed effect sizes
  m <- rma.mv(yi, vi, mods = as.formula(paste0("~ ", moderator, " - 1")), # fit random-effects meta-analysis model
              random = ~ 1 | index, data = data_es)
  list(model = m, data_es = data_es)
}

#### Function to calculate stats (I², R², subgroup tests) ####
calc_stats <- function(m, m1, moderator, data) {
  
  # I²
  Q  <- summary(m)$QE # cochran's Q
  df <- length(m$yi) - length(m$coef) # degrees of freedom
  I2 <- ((Q - df) / Q) * 100 # proportion of variance due to heterogeneity
  
  # R²
  fixed_var <- var(as.numeric(predict(m)$pred))
  total_var <- sum(m$sigma2) + fixed_var
  R2 <- fixed_var / total_var
  
  # Difference from pooled estimate
  overall <- m1$b[1] # overall estimate
  zvals   <- (m$b - overall) / m$se # perform the z-test for each level of the subgroup
  pvals   <- 2 * (1 - pnorm(abs(zvals))) # calculate the p-value for the z-test (two-tailed test) for each level

  coef_names <- rownames(coef(summary(m)))

  result_tbl <- data.frame(
    level   = gsub(paste0(moderator), "", coef_names),
    Coef    = as.numeric(m$b),
    SE      = as.numeric(m$se),
    Z_Value = zvals,
    P_Value = format(pvals, scientific = FALSE))
  
  # Calculating number of studies per subgroup level (k)
  k_tbl <- data %>% group_by(.data[[moderator]]) %>% 
    summarise(k=n(), .groups = "drop") %>%
    rename(level = !!moderator)
  
  # Calculating total number of colonies (ni) and number of colonies with co-occurrence (xi) within each subgroup level
  xi_tbl <- data %>% group_by(.data[[moderator]]) %>%
    summarise(total_ni = sum(ni), total_xi = sum(xi), .groups = "drop") %>%
    rename(level = !!moderator)
  
  # Extracting coefficients and CIs from each subgroup level
  coef_tbl <- coef(summary(m)) %>%
    as.data.frame() %>%
    tibble::rownames_to_column("rowname") %>%
    mutate(level = gsub(paste0(moderator), "", rowname),
                        subgroup=moderator)%>%
    left_join(k_tbl, by = "level") %>%
    mutate(estimate = transf.ilogit(estimate),
           ci.lb = transf.ilogit(ci.lb),
           ci.ub = transf.ilogit(ci.ub)) %>%
    left_join(result_tbl, by = "level") %>%
    left_join(xi_tbl, by = "level") %>%
    mutate(across(where(is.numeric), round, 2),
           est_ci = paste0(estimate, " [", ci.lb, " - ", ci.ub, "]"))
  
  list(I2 = I2, R2 = R2, table = coef_tbl)
}

#### Function for moderator orchard plot ####
plot_orchard <- function(model, data, moderator, title = NULL,
                         hline = NULL, angle = 45) {
  
  # Extract coefficients from the model
  coef_tbl <- coef(summary(model)) %>% as.data.frame()
  coef_tbl$level <- gsub(moderator, "", rownames(coef_tbl))
  
  # Order factor levels by descending estimate for plot
  moderator_order <- coef_tbl %>% arrange(-estimate) %>% pull(level)
  data[[moderator]] <- factor(data[[moderator]], levels = moderator_order)
  
  # Refit model with reordered factor
  formula_mod <- as.formula(paste0("~ ", moderator, " - 1"))
  model_ordered <- rma.mv(yi, vi, mods = formula_mod, random = ~1 | index, data = data)
  
  # Create orchard plot
  p <- orchaRd::orchard_plot(model_ordered, xlab = "Prevalence", mod = moderator, group = "index", angle = angle, 
                             g = FALSE, legend.pos = "none", transfm = "invlogit", twig.size = FALSE) +
    theme_classic() +
    theme(plot.title = element_text(face = "bold", size = 10),
          legend.position = "none")
  
  # Add line
  if (!is.null(hline)) {
    p <- p + geom_hline(yintercept = hline, linetype = "dashed",
                        color = "black", size = 0.6)
  }
  
  # Add title
  if (!is.null(title)) p <- p + ggtitle(title)
  
  return(p)
}

```

## Methodological variables
### Intracolony sampling - m2
```{r}
#### Getting data ready for model ####
data_grouped <- db%>%
  drop_na(quantity)%>%
  mutate(intracolony = case_when((intracolony_samples!=1 & time_points!=1) ~ "Multiple samples",
                                (intracolony_samples==1 & time_points==1) ~ "Single sample",
                                (intracolony_samples==1 & time_points!=1) ~ "Multiple samples",
                                (intracolony_samples!=1 & time_points==1) ~ "Multiple samples"))%>%
  group_by(index,symbionts, intracolony)

data_m2 <- prep_data(data_grouped, "intracolony")

#### Fit moderator model ####
m2_out <- fit_model(data_m2, "intracolony")
m2 <- m2_out$model
data_es <- m2_out$data_es

#### Stats + table ####
stats_m2 <- calc_stats(m2, m1, "intracolony", data_m2)
stats_m2$I2
stats_m2$R2
table_m2 <- stats_m2$table%>%
  select(subgroup, level, k, total_ni, total_xi, est_ci, P_Value) %>%
  arrange(est_ci)

#### Moderator plot ####
m2_plot <- plot_orchard(
  model = m2,        
  data = data_es,  
  moderator = "intracolony",
  title = "Intracolony sampling",
  hline = 0.096
) +
  scale_color_manual(values = scales::hue_pal(h = c(10, 30), l = 50, c = 70)(15)) +
  scale_fill_manual(values = scales::hue_pal(h = c(10, 30), l = 50, c = 70)(15))

```

### Method - m3
```{r}
#### Getting data ready for model ####
data_grouped <- db%>%
  drop_na(quantity)%>%
  group_by(index,symbionts, method)%>% #add moderators
  mutate(method=case_when(method=="WGS" ~ "Whole genome sequencing",
                          method=="qPCR" ~ "Quantitative PCR",
                          method=="ddPCR" ~ "Digital droplet PCR",
                          TRUE ~ method))

data_m3 <- prep_data(data_grouped, "method")

#### Fit moderator model ####
m3_out <- fit_model(data_m3, "method")
m3 <- m3_out$model
data_es <- m3_out$data_es

#### Stats + table ####
stats_m3 <- calc_stats(m3, m1, "method", data_m3)
stats_m3$I2
stats_m3$R2
table_m3 <- stats_m3$table%>%
  select(subgroup, level, k, total_ni, total_xi, est_ci, P_Value) %>%
  arrange(est_ci)

#### Moderator plot ####
m3_plot <- plot_orchard(
  model = m3,        
  data = data_es,  
  moderator = "method",
  title = "Genotyping method",
  hline = 0.096
) +
  scale_color_manual(values = scales::hue_pal(h = c(10, 30), l = 50, c = 70)(15)) +
  scale_fill_manual(values = scales::hue_pal(h = c(10, 30), l = 50, c = 70)(15))

```
###Method*intracolony sampling
```{r}

#Studies with high sensitivity techniques (e.g., NGS and qPCR) and multiple samples taken
gold_standard_studies <- db%>%
  drop_na(quantity)%>%
  mutate(intracolony = case_when((intracolony_samples!=1 & time_points!=1) ~ "Multiple samples",
                                (intracolony_samples==1 & time_points==1) ~ "Single sample",
                                (intracolony_samples==1 & time_points!=1) ~ "Multiple samples",
                                (intracolony_samples!=1 & time_points==1) ~ "Multiple samples"))%>%
  filter(intracolony=="Multiple samples")%>%
  filter(c(method=="qPCR" | method=="NGS"))

gold_standard_symbionts <- gold_standard_studies%>%
  drop_na(quantity)%>%filter(quantity>0)%>%
  group_by(symbionts, symbionts_name)%>%
  summarise(n=sum(quantity))%>%
  ungroup()%>%
  mutate(total=sum(n))%>%
  mutate(prop=n/total)

breaks = c("Cladocopium", "Durusdinium", "Cladocopium  + Durusdinium")

figure_s3_a <- ggplot(gold_standard_symbionts, aes(x=reorder(symbionts, -n), y=n, fill=symbionts_name))+
  geom_bar(stat="identity")+
  xlab("Symbiont presence")+ylab("Number of colonies")+
  scale_fill_manual(values = c("#f6e0b5", "#66545e", "#ce796b"), name="Symbiont presence")+
  theme_classic()+
  theme(legend.position = "none")

data_combined <- db%>%
  drop_na(quantity)%>%
  mutate(intracolony = case_when((intracolony_samples!=1 & time_points!=1) ~ "Multiple samples",
                                (intracolony_samples==1 & time_points==1) ~ "Single sample",
                                (intracolony_samples==1 & time_points!=1) ~ "Multiple samples",
                                (intracolony_samples!=1 & time_points==1) ~ "Multiple samples"))%>%
  group_by(index,symbionts, method, intracolony)%>% #add moderators
  summarise(number=sum(quantity))%>%
  drop_na()%>%
  pivot_wider(names_from = symbionts, values_from = number, values_fill=0) %>% 
  mutate(ni=C+D+CD)%>% mutate(xi=CD)%>%mutate(prop=xi/ni)%>%mutate(se = sqrt(prop * (1 -prop) / ni))%>%
 # mutate(method=as.factor(method))%>%
  drop_na()%>%
  group_by(method)%>%
  mutate(n_method=n())%>%
  filter(n_method>10) %>% #filter to methods with robust dataset
  mutate(combined=paste0(method,"_", intracolony))

dat <- escalc(xi=xi, ni=ni, data=data_combined, measure = "PLO") 

desired_order <- c("qPCR", "NGS", "ddPCR", "PacBio", "Sanger sequencing", "Cloning and sequencing", "RFLP", "DGGE", "SSCP",  "Genotyping arrays", "WGS", "454 pyrosequencing")

dat$method <- factor(dat$method, levels = desired_order)

gold_standard_model <- rma.mv(
  yi, vi,
  mods = ~ combined - 1,  # no intercept!
  method = "REML",
  random = ~1 | index,
  data = dat,
  test = "t")

res_tab <- coef(summary(gold_standard_model)) %>%
  as.data.frame() %>%
  rownames_to_column("term")%>% # term = levels of 'combined'
  mutate(
    prevalence      = transf.ilogit(estimate),  # back-transform estimate
    ci.lb_prev      = transf.ilogit(ci.lb),    # back-transform lower CI
    ci.ub_prev      = transf.ilogit(ci.ub)     # back-transform upper CI
  ) %>%
  select(term, prevalence, ci.lb_prev, ci.ub_prev)  # keep only relevant columns

#Use this for plotting
gold_standard_plot <- rma.mv(
  yi, vi,
  mods = ~ (method * intracolony) - 1,  # no intercept!
  method = "REML",
  random = ~1 | index,
  data = dat,
  test = "t")

HetModel <- orchaRd::mod_results(
  model = gold_standard_plot,
  mod = "method",
  group = "index",
  by = "intracolony")


# Get coefficient table

figure_s3_b <- orchaRd::orchard_plot(HetModel,xlab = "Prevalence", mod="method", group="index",angle = 45,g = FALSE, 
                      legend.pos = "bottom.right",  transfm="invlogit", twig.size = FALSE)+
  geom_hline(yintercept = 0.09, linetype = "dashed", color = "black", size = 0.6)  +
  scale_color_manual(values = scales::hue_pal(h = c(10, 75), l = 50, c = 70)(15))+
  scale_fill_manual(values = scales::hue_pal(h = c(10, 75), l = 50, c = 70)(15))+
   theme_classic() +
  theme(legend.position="bottom")

#### FIGURE S3 ####
figure_s3 <- figure_s3_b | figure_s3_a
ggsave("figure_s3.svg", figure_s3, width=10, height=6)

```



## Biological variables
### Life stage - m4
```{r}
#### Summary information ####
life_stage <- db%>%
  drop_na(quantity)%>%
  group_by(life_stage)%>%
  summarise(n=sum(quantity))%>%
  mutate(sum=sum(n),
         prop=n/sum)

#### Getting data ready for model ####
data_grouped <- db%>%
  drop_na(quantity)%>%
   group_by(index,symbionts, life_stage)%>%
   mutate(life_stage=case_when(life_stage=="Recruit" ~ "Recruit or juvenile", 
                              life_stage=="Juvenile" ~ "Recruit or juvenile",
                              TRUE ~ life_stage)) #combining recruits and juveniles into one category

data_m4 <- prep_data(data_grouped, "life_stage")

#### Fit moderator model ####
m4_out <- fit_model(data_m4, "life_stage")
m4 <- m4_out$model
data_es <- m4_out$data_es

#### Stats + table ####
stats_m4 <- calc_stats(m4, m1, "life_stage", data_m4)
stats_m4$I2
stats_m4$R2
table_m4 <- stats_m4$table%>%
  select(subgroup, level, k, total_ni, total_xi, est_ci, P_Value) %>%
  arrange(est_ci)

#### Moderator plot ####
m4_plot <- plot_orchard(
  model = m4,        
  data = data_es,  
  moderator = "life_stage",
  title = "Life stage",
  hline = 0.096
) +
  scale_color_manual(values = scales::hue_pal(h = c(75, 100))(25))+
  scale_fill_manual(values = scales::hue_pal(h = c(75, 100))(25))

```

### Reproductive mode - m5
```{r}
#### Summary information ####
# Number of species and genera that reproductive information was obtained for
reproduction_n <- db %>%
  distinct(genus, species, reproduction)%>%
  drop_na(reproduction)

# Proportion of corals within each reproductive mode
reproduction_prop <- db%>%
  select(genus,reproduction, quantity)%>%
  drop_na()%>%
  group_by(reproduction)%>%summarise(sum=sum(quantity))%>%
  mutate(prop = sum / sum(sum))

#### Getting data ready for model ####
data_grouped <- db%>%
  drop_na(quantity)%>%
  group_by(index,symbionts, reproduction)

data_m5 <- prep_data(data_grouped, "reproduction")

#### Fit moderator model ####
m5_out <- fit_model(data_m5, "reproduction")
m5 <- m5_out$model
data_es <- m5_out$data_es

#### Stats + table ####
stats_m5 <- calc_stats(m5, m1, "reproduction", data_m5)
stats_m5$I2
stats_m5$R2
table_m5 <- stats_m5$table%>%
  select(subgroup, level, k, total_ni, total_xi, est_ci, P_Value) %>%
  arrange(est_ci)

#### Moderator plot ####
m5_plot <- plot_orchard(
  model = m5,        
  data = data_es,  
  moderator = "reproduction",
  title = "Reproductive mode",
  hline = 0.096
) +
  scale_color_manual(values = scales::hue_pal(h = c(75, 100))(25))+
  scale_fill_manual(values = scales::hue_pal(h = c(75, 100))(25))

```

### Transmission mode - m6
```{r}
#### Summary information ####
# Number of species and genera that reproductive information was obtained for
provision_n <- db %>%
  distinct(genus, species, provision)%>%
  drop_na(provision)

# Proportion of corals within each reproductive mode
provision_prop <- db%>%
  select(genus,provision, quantity)%>%
  drop_na()%>%
  group_by(provision)%>%summarise(sum=sum(quantity))%>%
  mutate(prop = sum / sum(sum))

#### Getting data ready for model ####
data_grouped <- db%>%
  drop_na(quantity)%>%
  group_by(index,symbionts, provision)

data_m6 <- prep_data(data_grouped, "provision")

#### Fit moderator model ####
m6_out <- fit_model(data_m6, "provision")
m6 <- m6_out$model
data_es <- m6_out$data_es

#### Stats + table ####
stats_m6 <- calc_stats(m6, m1, "provision", data_m6)
stats_m6$I2
stats_m6$R2
table_m6 <- stats_m6$table%>%
  select(subgroup, level, k, total_ni, total_xi, est_ci, P_Value) %>%
  arrange(est_ci)

#### Moderator plot ####
m6_plot <- plot_orchard(
  model = m6,        
  data = data_es,  
  moderator = "provision",
  title = "Transmission mode",
  hline = 0.096
) +
  scale_color_manual(values = scales::hue_pal(h = c(75, 100))(25))+
  scale_fill_manual(values = scales::hue_pal(h = c(75, 100))(25))

```

### Morphology - m7
```{r}
#### Summary information ####
# Number of species and genera that reproductive information was obtained for
morpho_n <- db %>%
  distinct(genus, species, morpho)%>%
  drop_na()

# Proportion of corals within each reproductive mode
morpho_prop <- db%>%
  select(genus, species, morpho, quantity)%>%
  drop_na()%>%
  group_by(morpho)%>%summarise(sum=sum(quantity))%>%
  mutate(prop = sum / sum(sum))

#### Getting data ready for model ####
data_grouped <- db%>%
  drop_na(quantity)%>%
  group_by(index,symbionts, morpho)

data_m7 <- prep_data(data_grouped, "morpho")

#### Fit moderator model ####
m7_out <- fit_model(data_m7, "morpho")
m7 <- m7_out$model
data_es <- m7_out$data_es

#### Stats + table ####
stats_m7 <- calc_stats(m7, m1, "morpho", data_m7)
stats_m7$I2
stats_m7$R2
table_m7 <- stats_m7$table%>%
  select(subgroup, level, k, total_ni, total_xi, est_ci, P_Value) %>%
  arrange(est_ci)

#### Moderator plot ####
m7_plot <- plot_orchard(
  model = m7,        
  data = data_es,  
  moderator = "morpho",
  title = "Morphology",
  hline = 0.096
) +
  scale_color_manual(values = scales::hue_pal(h = c(75, 85))(25))+
  scale_fill_manual(values = scales::hue_pal(h = c(75, 85))(25))

```

## Spatial variables
### Region - m8
```{r}
#### Getting data ready for model ####
data_grouped <- db%>%
  drop_na(quantity)%>%
  drop_na(region)%>%filter(region!="NA")%>%
  group_by(index,symbionts, region)

data_m8 <- prep_data(data_grouped, "region")

#### Fit moderator model ####
m8_out <- fit_model(data_m8, "region")
m8 <- m8_out$model
data_es <- m8_out$data_es

#### Stats + table ####
stats_m8 <- calc_stats(m8, m1, "region", data_m8)
stats_m8$I2
stats_m8$R2
table_m8 <- stats_m8$table%>%
  select(subgroup, level, k, total_ni, total_xi, est_ci, P_Value) %>%
  arrange(est_ci)

#### Moderator plot ####
m8_plot <- plot_orchard(
  model = m8,        
  data = data_es,  
  moderator = "region",
  title = "Region",
  hline = 0.096
) +
   scale_color_manual(values = rep("darkolivegreen", 11)) +
scale_fill_manual(values = rep("darkolivegreen", 11))

```

### Depth - m9
```{r}
#Depth summary
depth <- db%>%
  select(row, index, depth, symbionts, quantity)%>%
  mutate(depth=gsub('m','',depth))%>%
  separate(depth, into=c("min", "max"), "-") %>%
  mutate(max=case_when(is.na(max) ~ min,
                       TRUE~max))%>%
  mutate(depth_type = case_when(is.na(min) | tolower(min) %in% c("nd") ~ "not given",
                                is.na(min) | tolower(min) %in% c("na") ~ "not applicable",
                                str_detect(max, "[<>]") ~ "range",
                                min == max ~ "discrete",
                                TRUE  ~ "range"))%>%
  distinct(index, depth_type)

depth_priority <- c("discrete" = 1, "range" = 2, "not applicable" = 3, "not given" = 3)

depth_summary <- depth %>%
  mutate(depth_rank = recode(depth_type, !!!depth_priority)) %>%
  group_by(index) %>%
  slice_min(order_by = depth_rank, n = 1, with_ties = FALSE) %>%
  ungroup() %>%
  select(index, depth_type)%>%
  group_by(depth_type)%>%summarise(n=n())

#### Getting data ready for model ####
data_m9 <- db%>%
  drop_na(quantity)%>%
  select(row, index, depth, symbionts, quantity)%>%
  separate(depth, into=c("min", "max"), "-") %>%
  mutate(max=case_when(is.na(max) ~ min,
                       TRUE~max))%>%
  mutate(depth_type = case_when(is.na(min) | tolower(min) %in% c("na", "nd") ~ "not given",
                                str_detect(max, "[<>]") ~ "range",
                                min == max ~ "discrete",
                                TRUE  ~ "range"))%>%
  filter(depth_type=="discrete")%>%
  drop_na(c(quantity))%>%
  mutate(max=as.numeric(max))%>%
  group_by(index,symbionts, max)%>%
  summarise(number = sum(quantity)) %>%
    pivot_wider(names_from = symbionts, values_from = number, values_fill = 0) %>%
    mutate(ni   = C + D + CD, #total colonies
           xi   = CD, #colonies with co-occurrence
           prop = xi / ni, #prevalence/proportion of colonies with co-occurrence
           se   = sqrt(prop * (1 - prop) / ni))%>%
 ungroup()%>% mutate(total_sum=sum(ni))%>%
  filter(max<25) #restricted dataset (presented in main text). turn off to get unrestricted dataset (in supplementary)
  
#### Fit moderator model ####
m9_in <- escalc(xi=xi, ni=ni, data=data_m9, measure = "PLO") 
m9 <- rma.mv(yi, vi, mods = ~ max , random=~1|index, data = m9_in)
data_es <- m9$data_es

#### Stats + table ####
Q <- summary(m9)$QE
df <- length(m9$yi) - length(m9$coef)  # Number of studies minus the number of coefficients
I2 <- ((Q - df) / Q) * 100
I2

fixed_var <- var(as.numeric(predict(m9)$pred))
total_var <- sum(m9$sigma2) + fixed_var
R2_m <- fixed_var / total_var
R2_m

stats_m9 <- data.frame(I2 = I2, R2 = R2_m)

k_tbl <- data_m9 %>%
  ungroup()%>%
  summarise(k = n())%>%
  mutate(level="max")

xi_tbl <- data_m9 %>%
  ungroup()%>%
  summarise(total_ni = sum(ni),
            total_xi = sum(xi))%>%
  mutate(level="max")


table_m9 <- k_tbl %>% left_join(xi_tbl) %>%
  mutate(subgroup = "depth",
         level = NA,
         est_ci  = NA,
         P_Value = NA) %>%
  select(subgroup, level, k, total_ni, total_xi, est_ci, P_Value)


#### Moderator plot ####
p <- orchaRd::bubble_plot(m9, group = "index", mod = "max", 
                          xlab = "Depth (m)", 
                          ylab="Prevalence",
                          legend.pos = "none", 
                          transfm = "invlogit")

# Force fill and color manually in the first layer (likely points)
p$layers[[1]]$aes_params$fill <- "darkolivegreen"
p$layers[[1]]$aes_params$colour <- "darkolivegreen"


m9_plot <- p + theme_classic() +
    ggtitle("Depth") +
    theme(plot.title = element_text(face = "bold", size = 10),
          legend.position = "none")


# m9p_full <- p + theme_classic() +
#     ggtitle("Depth (unrestricted)") +
#     theme(plot.title = element_text(face = "bold", size = 10),
#           legend.position = "none")

```

### Distance from shore - m10
```{r}
# Only use coordinates that were reported in the study
eligible_coords <- db%>%
  filter(coord_retrieval=="Reported")%>%
  distinct(row, index, lat, lon)

# Distance to nearest land (incl. islands)
points_sf <- eligible_coords %>%
  filter(!is.na(lat), !is.na(lon)) %>%
  filter(lat!="ND") %>%
  st_as_sf(coords = c("lon", "lat"), crs = 4326)

coastline <- ne_coastline(scale = 10, returnclass = "sf")
coastline <- st_make_valid(coastline)

points_proj <- st_transform(points_sf, crs = 3395)
coastline_proj <- st_transform(coastline, crs = 3395)

dist_matrix <- st_distance(points_proj, coastline_proj)
min_distances_m <- apply(dist_matrix, 1, min)  # in meters

# Get the minimum distance for each point (in meters)
points_with_dist_coastline <- points_sf %>%
  mutate(
    dist_to_coastline_m = set_units(round(min_distances_m, 2), "m"),
    dist_to_coastline_km = set_units(round(min_distances_m / 1000, 2), "km")
  )

points_final <- st_transform(points_with_dist_coastline, crs = 4326)%>%
  mutate(
    lon = st_coordinates(.)[, 1],
    lat = st_coordinates(.)[, 2])%>%
  as.data.frame()%>%
  select(row, index, dist_to_coastline_m,dist_to_coastline_km )

# After importing and calculating in qgis
distance <- db%>%
  drop_na(quantity)%>%
  left_join(points_final)

#### Getting data ready for model ####
data_m10 <- distance%>%
  drop_na(c(lat))%>%
  select(index,symbionts, dist_to_coastline_km, quantity)%>%
  mutate(dist_to_coastline_km = as.numeric(dist_to_coastline_km))%>%
  drop_na(dist_to_coastline_km)%>%
  group_by(index,symbionts, dist_to_coastline_km)%>%
  summarise(number = sum(quantity)) %>%
    pivot_wider(names_from = symbionts, values_from = number, values_fill = 0) %>%
    mutate(ni   = C + D + CD, # total colonies
           xi   = CD, # colonies with co-occurrence
           prop = xi / ni, # prevalence/proportion of colonies with co-occurrence
           se   = sqrt(prop * (1 - prop) / ni))%>%ungroup()%>% mutate(total_sum=sum(ni))%>%
  filter(dist_to_coastline_km<100) # restricted dataset (presented in main text). turn off to get unrestricted dataset (in supplementary)
  
#### Fit moderator model ####
m10_in <- escalc(xi=xi, ni=ni, data=data_m10, measure = "PLO") 
m10 <- rma.mv(yi, vi, mods = ~ dist_to_coastline_km , random=~1|index, data = m10_in)
data_es <- m10$data_es

#### Stats + table ####
Q <- summary(m10)$QE
df <- length(m10$yi) - length(m10$coef)  # Number of studies minus the number of coefficients
I2 <- ((Q - df) / Q) * 100
I2

fixed_var <- var(as.numeric(predict(m10)$pred))
total_var <- sum(m10$sigma2) + fixed_var
R2_m <- fixed_var / total_var
R2_m

stats_m10 <- data.frame(I2 = I2, R2 = R2_m)

k_tbl <- data_m10 %>%
  ungroup()%>%
  summarise(k = n())%>%
  mutate(level="dist_to_coastline_km")

xi_tbl <- data_m10 %>%
  ungroup()%>%
  summarise(total_ni = sum(ni),
            total_xi = sum(xi))%>%
  mutate(level="dist_to_coastline_km")


table_m10 <- k_tbl %>% left_join(xi_tbl) %>%
  mutate(subgroup = "dist_to_coastline_km",
         level = NA,
         est_ci  = NA,
         P_Value = NA) %>%
  select(subgroup, level, k, total_ni, total_xi, est_ci, P_Value)


#### Moderator plot ####
p <- orchaRd::bubble_plot(m10, group = "index", mod = "dist_to_coastline_km", 
                          xlab = "Distance from shore (km)", 
                          ylab="Prevalence",
                          legend.pos = "none", 
                          transfm = "invlogit")

# Force fill and color manually in the first layer (likely points)
p$layers[[1]]$aes_params$fill <- "darkolivegreen"
p$layers[[1]]$aes_params$colour <- "darkolivegreen"


m10_plot <- p + theme_classic() +
    ggtitle("Distance from shore") +
    theme(plot.title = element_text(face = "bold", size = 10),
          legend.position = "none")


# m10p_full <- p + theme_classic() +
#     ggtitle("Depth (unrestricted)") +
#     theme(plot.title = element_text(face = "bold", size = 10),
#           legend.position = "none")

```

## Study-level variables
### Study type - m11
```{r}
#### Getting data ready for model ####
data_grouped <- db%>%
  drop_na(quantity)%>%
  drop_na(c(quantity))%>%
  group_by(index,symbionts, type)

data_m11 <- prep_data(data_grouped, "type")

#### Fit moderator model ####
m11_out <- fit_model(data_m11, "type")
m11 <- m11_out$model
data_es <- m11_out$data_es

#### Stats + table ####
stats_m11 <- calc_stats(m11, m1, "type", data_m11)
stats_m11$I2
stats_m11$R2
table_m11 <- stats_m11$table%>%
  select(subgroup, level, k, total_ni, total_xi, est_ci, P_Value) %>%
  arrange(est_ci)

#### Moderator plot ####
m11_plot <- plot_orchard(
  model = m11,        
  data = data_es,  
  moderator = "type",
  title = "Study type",
  hline = 0.096
) +
  scale_color_manual(values = rep("steelblue4", 10)) +
  scale_fill_manual(values = rep("steelblue4", 10))

```

### Year - m12
```{r}
#### Getting data ready for model ####
data_m12 <- db%>%
  drop_na(quantity)%>%
  select(row, index, genus, species, quantity, time_points, intracolony_samples, sampling_year, symbionts)%>%
  mutate(across(c(quantity, time_points, intracolony_samples), as.numeric))%>%
  drop_na()%>%
#  mutate(total_colonies = quantity * intracolony_samples)%>%
  mutate(sampling_year = str_split(sampling_year, ";\\s*")) %>%
  unnest(sampling_year) %>%
  mutate(year = str_extract(sampling_year, "\\d{4}"))%>%
  group_by(index,symbionts, year) %>%
  mutate(year=as.numeric(year))%>%
  summarise(number = sum(quantity)) %>%
    pivot_wider(names_from = symbionts, values_from = number, values_fill = 0) %>%
    mutate(ni   = C + D + CD, # total colonies
           xi   = CD, # colonies with co-occurrence
           prop = xi / ni, # prevalence/proportion of colonies with co-occurrence
           se   = sqrt(prop * (1 - prop) / ni))


#### Fit moderator model ####
m12_in <- escalc(xi=xi, ni=ni, data=data_m12, measure = "PLO") 
m12 <- rma.mv(yi, vi, mods = ~ year , random=~1|index, data = m12_in)
data_es <- m12$data_es

#### Stats + table ####
Q <- summary(m12)$QE
df <- length(m12$yi) - length(m12$coef)  # number of studies minus the number of coefficients
I2 <- ((Q - df) / Q) * 100
I2

fixed_var <- var(as.numeric(predict(m12)$pred))
total_var <- sum(m12$sigma2) + fixed_var
R2_m <- fixed_var / total_var
R2_m

stats_m12 <- data.frame(I2 = I2, R2 = R2_m)

k_tbl <- data_m12 %>%
  ungroup()%>%
  summarise(k = n())%>%
  mutate(level="max")

xi_tbl <- data_m12 %>%
  ungroup()%>%
  summarise(total_ni = sum(ni),
            total_xi = sum(xi))%>%
  mutate(level="max")


table_m12 <- k_tbl %>% left_join(xi_tbl) %>%
  mutate(subgroup = "year",
         level = NA,
         est_ci  = NA,
         P_Value = NA) %>%
  select(subgroup, level, k, total_ni, total_xi, est_ci, P_Value)


#### Moderator plot ####
p <- orchaRd::bubble_plot(m12, group = "index", mod = "year", 
                          xlab = "Year sampled", 
                          ylab = "Prevalence",
                          legend.pos = "none", 
                          transfm = "invlogit")

# Force fill and color manually in the first layer (likely points)
p$layers[[1]]$aes_params$fill <- "steelblue4"
p$layers[[1]]$aes_params$colour <- "steelblue4"

# Then apply styling
m12_plot <- p + theme_classic() +
    ggtitle("Year sampled") +
    theme(plot.title = element_text(face = "bold", size = 10),
          legend.position = "none")
```

### Sample size - m13
```{r}

#### Getting data ready for model ####
data_m13 <- db%>%
  drop_na(quantity)%>%
  group_by(index,symbionts) %>%
#  filter(index!="1320")%>%
  summarise(number = sum(quantity)) %>%
    pivot_wider(names_from = symbionts, values_from = number, values_fill = 0) %>%
    mutate(ni   = C + D + CD, # total colonies
           xi   = CD, # colonies with co-occurrence
           prop = xi / ni, # prevalence/proportion of colonies with co-occurrence
           se   = sqrt(prop * (1 - prop) / ni))%>%
  drop_na(ni)


#### Fit moderator model ####
m13_in <- escalc(xi=xi, ni=ni, data=data_m13, measure = "PLO") 
m13 <- rma.mv(yi, vi, mods = ~ ni , random=~1|index, data = m13_in)
data_es <- m13$data_es

#### Stats + table ####
Q <- summary(m13)$QE
df <- length(m13$yi) - length(m13$coef)  # number of studies minus the number of coefficients
I2 <- ((Q - df) / Q) * 100
I2

fixed_var <- var(as.numeric(predict(m13)$pred))
total_var <- sum(m13$sigma2) + fixed_var
R2_m <- fixed_var / total_var
R2_m

stats_m13 <- data.frame(I2 = I2, R2 = R2_m)

k_tbl <- data_m13 %>%
  ungroup()%>%
  summarise(k = n())%>%
  mutate(level="ni")

xi_tbl <- data_m13 %>%
  ungroup()%>%
  summarise(total_ni = sum(ni),
            total_xi = sum(xi))%>%
  mutate(level="ni")


table_m13 <- k_tbl %>% left_join(xi_tbl) %>%
  mutate(subgroup = "sample_size",
         level = NA,
         est_ci  = NA,
         P_Value = NA) %>%
  select(subgroup, level, k, total_ni, total_xi, est_ci, P_Value)


#### Moderator plot ####
p <- orchaRd::bubble_plot(m13, group = "index", mod = "ni", 
                          xlab = "Sample size", 
                          ylab = "Prevalence",
                          legend.pos = "none", 
                          transfm = "invlogit")

# Force fill and color manually in the first layer (likely points)
p$layers[[1]]$aes_params$fill <- "steelblue4"
p$layers[[1]]$aes_params$colour <- "steelblue4"

# Then apply styling
m13_plot <- p + theme_classic() +
    ggtitle("Sample size") +
    theme(plot.title = element_text(face = "bold", size = 10),
          legend.position = "none")


```

## FIGURE 4
```{r}

orchards <- (m1_plot /  
  ((m2_plot / m3_plot / m4_plot / m5_plot / m6_plot / m7_plot + plot_layout(heights = c(0.5, 1, 0.5, 0.3, 0.3, 1))) |
   (m8_plot / m11_plot  + plot_layout(heights = c(1, 1))) |
   (m9_plot / m10_plot /m12_plot / m13_plot  + plot_layout(heights = c(1, 1, 1,1)))))+
  plot_layout(heights = c(0.2, 2.5)) + 
  plot_annotation(tag_levels = "A")

ggsave("figure_4.svg", orchards, width=15, height=14)

#### Figure S4 ####
figure_s4 <- m9p_full / m10p_full
ggsave("figure_s4.svg", figure_s4, width=10, height=8)


```

## TABLE 2
```{r}

table_2 <- rbind(table_m2, table_m3, table_m4, table_m5, table_m6, table_m7, table_m8, table_m9, table_m10, table_m11, table_m12, table_m13)%>%
  write_csv("table_2.csv")


I2_R2_table <- data.frame(moderator = c("m2","m3","m4","m5","m6","m7","m8","m9","m10", "m11", "m12", "m13"),
  I2 = c(stats_m2$I2, stats_m3$I2, stats_m4$I2, stats_m5$I2,stats_m6$I2, stats_m7$I2, stats_m8$I2, stats_m9$I2, stats_m10$I2, stats_m11$I2, stats_m12$I2, stats_m13$I2),
  R2 = c(stats_m2$R2, stats_m3$R2, stats_m4$R2, stats_m5$R2,stats_m6$R2, stats_m7$R2, stats_m8$R2, stats_m9$R2, stats_m10$R2, stats_m11$R2, stats_m12$R2, stats_m13$R2))
```

# PART 3: CORAL GENERA/PGLMM
## Coral genera
```{r}
#Total number of genera
genus_n <- db%>%
  distinct(genus)%>%
  filter(!genus %in% c("NA", "ND"))

#Number of genera exhibiting co-occurrence 
genus_CD <- db%>%
  distinct(genus, symbionts)%>%
  filter(symbionts=="CD")

#Total number of families
family_n <- db%>%
  distinct(family)%>%
  filter(!family %in% c("NA", "ND"))%>%
  drop_na()

#Number of families exhibiting co-occurrence 
family_CD <- db%>%
  distinct(family, symbionts)%>%
  filter(!family %in% c("NA", "ND"))%>%
  drop_na()%>%
  filter(symbionts=="CD")
  
symbionts_bygenus <- db%>%
  filter(!genus %in% c("NA", "ND"))%>% #turn this off and get 36008 colonies
  select(genus, quantity, symbionts, symbionts_name)%>%
  drop_na(quantity)%>%
  group_by(genus, symbionts_name)%>%
  summarise(symbiont_quantity = sum(quantity), .groups = "drop") %>% # count per genus × symbiont
  mutate(genus = str_to_title(genus)) %>%
  group_by(genus) %>%
  mutate(genus_quantity = sum(symbiont_quantity), # total per genus
         symbiont_prop  = symbiont_quantity / genus_quantity)%>% # proportion per symbiont
  ungroup() %>%
  mutate(total = sum(symbiont_quantity))


symbionts_byfamily <- db%>%
  filter(!family %in% c("NA", "ND"))%>% 
  drop_na(family)%>%
  select(family, quantity, symbionts, symbionts_name)%>%
  drop_na(quantity)%>%
  group_by(family, symbionts_name)%>%
  summarise(symbiont_quantity = sum(quantity), .groups = "drop") %>% # count per genus × symbiont
  mutate(family = str_to_title(family)) %>%
  group_by(family) %>%
  mutate(family_quantity = sum(symbiont_quantity), # total per genus
         symbiont_prop  = symbiont_quantity / family_quantity)%>% # proportion per symbiont
  ungroup() %>%
  mutate(total = sum(symbiont_quantity))


#### FIGURE S5 ####
genus_barplot <- ggplot(symbionts_bygenus,aes(y=reorder(genus, genus_quantity),x=symbiont_quantity))+
  geom_bar(stat="identity",aes(fill = symbionts_name))+
  xlab("Number of colonies across all papers")+
  ylab("Genus")+
  #scale_fill_tableau(palette="Tableau 20",name = "Symbiont presence") +
  scale_fill_manual(breaks=breaks, values = c("#f6e0b5", "#66545e", "#ce796b"),name="Symbiont presence")+
#  scale_fill_tableau(palette = "Miller Stone",name = "Symbiont presence")+
  theme_classic()+
  theme(axis.text.y = element_text(size = 7),
        axis.title.y = element_text(size = 9),
        axis.text.x = element_text(size = 7),
        axis.title.x = element_text(size = 9),
        legend.position = "bottom")

family_barplot <- ggplot(symbionts_byfamily,aes(y=reorder(family,family_quantity),x=symbiont_quantity))+
  geom_bar(stat="identity",aes(fill = symbionts_name))+
  xlab("Number of colonies across all papers")+
  ylab("Genus")+
  #scale_fill_tableau(palette="Tableau 20",name = "Symbiont presence") +
  scale_fill_manual(breaks=breaks, values = c("#f6e0b5", "#66545e", "#ce796b"),name="Symbiont presence")+
#  scale_fill_tableau(palette = "Miller Stone",name = "Symbiont presence")+
  theme_classic()+
  theme(axis.text.y = element_text(size = 7),
        axis.title.y = element_text(size = 9),
        axis.text.x = element_text(size = 7),
        axis.title.x = element_text(size = 9),
        legend.position = "bottom")


figure_s5 <- (genus_barplot | family_barplot) + plot_annotation(tag_levels = "A") +  plot_layout(guides = "collect") & theme(legend.position = 'bottom')
ggsave("figure_s5.svg", figure_s5, width=8, height=12)

```

## Taxonomic tree
```{r}

#### Preparing coral phylogeny ####
coral_tree <- read.tree("../all-best-tree-jan2021.raxml.support") #tree obtained from Quek et al. (2023)

x <- as.treedata(coral_tree) %>%
  as_tibble() %>%
  separate(label, into = c("a", "b", "c", "d", "e"), remove = FALSE) %>% # separate tip labels into metadata columns
  mutate(b = case_when(b == "Robust" ~ c, TRUE ~ b)) # b is where most of the genera names are

genus <- x %>% filter(!is.na(b)) %>% distinct(b) %>% pull() # extract the unique genera for later use

#### Trim tree to one tip per genus ####
trimmed_tree <- as.phylo(coral_tree)

# Loop through each genus and drop extra species, keeping the first one
for(one_tip in genus) {
    species <- grep(one_tip, trimmed_tree$tip.label) # find the tips matching the species name
    trimmed_tree <- drop.tip(trimmed_tree, trimmed_tree$tip.label[species[-1]]) # removing all the species but the first one
}

# Make the Corallimorpharia the root (Discosoma, Rhodactis, Amplexidiscus, Ricordea, Corynactis)
trimmed_tree <- root(trimmed_tree, node = 134) 

trimmed_tree_df <- as.tibble(trimmed_tree)

#### Plotting tree ####
p <- ggtree(trimmed_tree)

p$data <- p$data %>% separate(label, into = c("a", "b", "c", "d", "e"), remove = FALSE) %>%
  mutate(b = case_when(b == "Robust" ~ c, TRUE ~ b))  # again, make the tip labels manageable as above
 # mutate(b = str_to_lower(b))

p <- p + geom_tiplab(size = 3.5, aes(label = paste0("italic(", b, ")")), parse = TRUE, align = TRUE)

#### Prepare metadata table linking tips to genus ####
scler_df <- p$data %>% filter(isTip == TRUE) %>%
  select(label, b)

mismatch <- left_join(symbionts_bygenus, scler_df, by = c("genus" = "b"))

# Keep only rows that exist in both datasets (tree + symbiont)
in_both <- mismatch%>%
  distinct(genus, label)

# MISSING FROM TREE
# filt_missing <- c("cladocora", "stephanocoenia", "blastomussa", "pleuractis", "mycetophyllia", "colpophyllia", "stylocoeniella", "scolymia", "mussismilia", "dichocoenia", "diploria", "mussa", "manicina", "halomitra", "euphyliia", "anacropora", "cycloseris", "symphyllia", "favia", "mussidae", "fungiidae")

matrix <- left_join(scler_df, symbionts_bygenus, by = c("b" = "genus"))
```

## Genus - m14
Meta-analysis for coral genera
```{r}
data_grouped <- db%>%
  drop_na(c(quantity))%>%
  group_by(index, symbionts, genus)%>%
  mutate(genus = str_to_title(genus))           

data_m14 <- prep_data(data_grouped, "genus")%>%
   rename(b="genus")%>%left_join(scler_df)

#### Fit moderator model ####
m14_out <- fit_model(data_m14, "label")
m14 <- m14_out$model
data_es <- m14_out$data_es

#### Stats + table ####
stats_m14 <- calc_stats(m14, m1, "label", data_m14)
stats_m14$I2
stats_m14$R2
table_m14 <- stats_m14$table%>%
  select(subgroup, level, k, total_ni, total_xi, est_ci, P_Value) %>%
  arrange(est_ci)

# Find genera which have above and below 10 studies, as above 10 studies is likely to be more robust. Will use this threshold for plotting Figure 5.
genus_es <- stats_m14$table%>%
  select(level, estimate, ci.lb, ci.ub, k)%>%
  rename(label="level")%>%
  mutate(k=case_when(k < 10 ~ "<10",
                     k >= 10 ~ ">10")) 

```

## FIGURE 5
```{r}
symbionts_byregion <- db%>%
  drop_na(quantity)%>%
  group_by(genus, region)%>%
  summarise(region_quantity = sum(quantity))%>%
  mutate(genus = str_to_title(genus)) 

matrix_region <- left_join(scler_df, symbionts_byregion, by = c("b" = "genus"))%>%
  mutate(region=as.factor(region))%>%
  drop_na()%>%
  mutate(b = str_to_title(b))%>%
  pivot_wider(names_from = region, values_from = region_quantity)%>%
  column_to_rownames(var='label')%>%
  select(-b)

# Tree and heatmap showing number of colonies sampled per genus and region
figure_5a <- gheatmap(p, matrix_region, offset=0.5, width=1, font.size=2.5, 
        colnames_angle=90, hjust=-0.1, colnames_position = "bottom")+
  scale_fill_viridis(
    option = "G",  # Choose the color palette option
   # trans = "log",  # Logarithmic scale for better contrast in the lower end
    direction =- 1,
    na.value = "transparent",
    name="Colonies sampled"
  )+
  theme(legend.position = "right")

#Adding symbiont data to tree figure 
figure_5b <- figure_5a+new_scale_fill()

figure_5c<-facet_plot(figure_5b, panel = 'Symbiont data (relative)', data = matrix,
                     geom = geom_barh,
                     mapping = aes(x = symbiont_prop, fill = symbionts_name), stat = 'identity')+
                scale_fill_manual(values = c("#f6e0b5", "#66545e", "#ce796b"), name="Symbiont category")+
  theme(panel.spacing = unit(0.1, "lines"))  # Reduce the space between panels (if applicable)

# Adding co-occurrence estimates to figure
figure_5d <- facet_plot(figure_5c, panel = 'Co-occurrence estimate', data=genus_es, 
           geom=geom_pointrange,
           mapping = aes(x = estimate,  xmin = ci.lb, xmax = ci.ub, color=k), size = 0.1)+
  scale_color_manual(values = c("lightgrey", "grey2"), name="Number of studies")+
  new_scale_fill() +
  theme(
    panel.spacing = unit(0.1, "lines")  # Reduce the space between panels (if applicable)
  )
  
# Vertical reference line at 0.095 (global estimate)
figure_5e <- facet_plot(figure_5d,panel = 'Co-occurrence estimate', data=genus_es,
    geom = geom_vline,
    mapping = aes(xintercept = 0.095),
    linetype = "dashed",
    color = "grey2",
    size = 0.3
  )

figure_5f <- figure_5e + theme_tree2() +theme_classic()+
    theme(legend.position="bottom",
          axis.text.y = element_blank(),
          legend.title = element_text(face="bold"))

figure_5 <- facet_widths(figure_5f, widths = c(1.2, 0.5, 0.5)) 

ggsave("figure_5.svg",figure_5, height=15, width=14)

```

## Phylogenetic linear mixed model (PGLMM)
```{r}
pglmm_data <- db%>%
  drop_na(quantity)%>%
  filter(region!="NA")%>%filter(region!="ND")%>%
  select(index, genus, region,method, intracolony_samples, time_points, quantity, symbionts)

all_symbionts <- c("C", "CD", "D")

complete_grid <- pglmm_data %>%
  distinct(index, genus, region) %>%
  crossing(symbionts = all_symbionts)

final_data <- complete_grid %>%
  left_join(pglmm_data, by = c("index", "genus", "region", "symbionts")) %>%
  mutate(genus = str_to_title(genus))%>%
  arrange(index,  genus, region, symbionts)%>%
   mutate(
    quantity = replace_na(quantity, 0),
    region = replace_na(region, "NA"))%>%
  mutate(presence = case_when(quantity > 0 ~ 1,
                                 TRUE ~ 0))%>%
  select(index, genus, region,symbionts, quantity, presence)%>%
  filter(symbionts=="CD")%>%
  rename(b="genus")

pglmm_matrix<- left_join(final_data, scler_df)

pglmm_data_cleaned <- pglmm_matrix %>%
  filter(label %in% trimmed_tree$tip.label)%>%  # match phylogeny tips
  filter(symbionts=="CD")%>%
  filter(!is.na(quantity), !is.na(region), !is.na(symbionts))%>%
  filter(!c(region=="Brazil" | region=="South Asia"))%>% # drop regions that don't have enough statistical power
  mutate(phylo=label)

pglmm_genera <- pglmm_data_cleaned%>%distinct(label)

# Calculate the Variance Co-Variance (VCV) matrix of the phylogeny (i.e., branch length seperating species)
vcv <- vcv(trimmed_tree, corr = TRUE)
#Keep only the genera in the dataset
vcv_cleaned <- vcv[pglmm_genera$label, pglmm_genera$label]
vcv_df <- as.matrix(vcv_cleaned)

table(pglmm_data_cleaned$region, pglmm_data_cleaned$presence)

model_binomial <- pglmm(
  presence ~ region + 
    (1 | label__) +            # genus random effect, phylogenetically structured
    (1 | label__@region),      # phylogeny × region interaction
  data = pglmm_data_cleaned,
  family = "binomial",  # because coexistence is binomial 
  cov_ranef = list(label = vcv_cleaned), # provide phylogenetic covariance
  REML = TRUE
)

summary(model_binomial)
summary(model_binomial)$var.ranef
# 1 | label       = unstructured genus effect
# 1 | label__     = phylogenetic genus effect
# 1 | label__@region = phylogenetic genus × region interaction

#Likelihood ratio tests on random effects
test_label <- phyr::pglmm_profile_LRT(model_binomial, re.number = 1) # unstructured genus effect
test_label_ <- phyr::pglmm_profile_LRT(model_binomial, re.number = 2) # phylogenetic genus effect
test_label_region <- phyr::pglmm_profile_LRT(model_binomial, re.number = 3) # phylogeny x region interaction

```

#PART 4: CO-PHYLOGENY ANALYSIS
## Import profile data
```{r}
rd <- sort(list.files("symportal_datasets/", recursive = "false", full.names = TRUE))
md <- sort(list.files("symportal_metadata/", recursive = "false", full.names = TRUE))

rd
md

merged_data <- data.frame() # empty data frame to catch all the data
for(i in 1:length(rd)){
  seq_path <- paste0(rd[i], "/post_med_seqs/")
  seq_file <- list.files(seq_path, pattern = "seqs.absolute.abund_and_meta.txt", recursive = FALSE, full.names = TRUE)
  seqs <- read_tsv(seq_file) %>%
  filter(!(is.na(sample_name)))
  
  fasta_file <- list.files(seq_path, pattern = ".fasta", recursive = FALSE, full.names = TRUE)
  fasta <- read_fasta_df(fasta_file)
  
  seqs_long <- seqs %>%
  dplyr::select(sample_name, sample_type, host_genus,	host_species,	
                collection_latitude, collection_longitude, collection_date, 
                collection_depth:last_col()) %>% # Select sample_names and the each column contain sequence count data
  pivot_longer(-sample_name:-collection_depth) %>% # make into long dataframe
  filter(value > 0) %>% # Remove zero values
  filter(!(is.na(sample_name))) %>%
  mutate(index = paste0(basename(rd[i]), ".pdf")) %>%
    left_join(., fasta)
  
  meta <- read_csv(md[i]) %>%
    mutate(index = case_when(str_detect(index, ".pdf") ~ index,
                             TRUE ~ paste0(index, ".pdf")))
  
  seqs_long <- seqs_long %>% left_join(., meta)
  
  merged_data <- rbind(merged_data, seqs_long)
}

merged_data <- merged_data %>%
    mutate(sample_name_index = paste0(sample_name, "-", index))


merged_profs <- data.frame()
for(i in 1:length(rd)){
  prof_path <- paste0(rd[i], "/its2_type_profiles/")
  prof_file <- list.files(prof_path, pattern = "profiles.absolute.abund_and_meta.txt", recursive = FALSE, full.names = TRUE)
  profs <- read_tsv(prof_file, skip = 6) %>%
  dplyr::rename(sample_name = "...2") %>%
  filter(!(is.na(sample_name)))
  
  profs_long <- profs %>%
  dplyr::select(sample_name:last_col()) %>% # Select sample_names and the each column contain sequence count data
  pivot_longer(-sample_name) %>% # make into long dataframe
  filter(value > 0) %>% # Remove zero values
  filter(!(is.na(sample_name))) %>%
  mutate(index = paste0(basename(rd[i]), ".pdf"))
  
  meta <- read_csv(md[i]) %>%
    mutate(index = case_when(str_detect(index, ".pdf") ~ index,
                             TRUE ~ paste0(index, ".pdf")))
  
  profs_long <- profs_long %>% left_join(., meta)
  
  merged_profs <- rbind(merged_profs, profs_long)
}

merged_profs <- merged_profs  %>%
    mutate(sample_name_index = paste0(sample_name, "-", index)) %>%
  distinct()

write_csv(merged_data, "merged_data.csv")
write_csv(merged_profs, "merged_profs.csv")
```

```{r}
merged_profs <- read_csv("merged_profs.csv")
merged_data <- read_csv("merged_data.csv")
```

## QA/QC of symportal data
```{r}
# Filter by sample sequencing depth. Samples must have minimum of 1000 sequences.
totals <- merged_data %>%
  group_by(index, sample_name) %>%
  summarise(sample_sum = sum(value)) %>%
  ungroup() %>%
  arrange(sample_sum) %>%
  mutate(sample_name = fct_inorder(sample_name)) %>%
  mutate(keep = case_when(sample_sum > 1000 ~ "keep",
                          TRUE ~ "remove"))

# Remove sequences below relative abundance threshold. See section on CD:D ratio by filtering threshold (PART 5 of code)
filt_thresh <- 0.0103

# Apply filtering threshold and perform general cleaning steps
merged_clean <- merged_data %>%
  left_join(., totals) %>%
  filter(keep == "keep") %>% # minimum of 1000 sequences in sample
  mutate(published = case_when(is.na(published) ~ "n",
                               TRUE ~ published)) %>% # some symportal samples seem to not be published in the accompanying papers. remove these.
  filter(published != "n") %>% # if there were a clear subset of samples that were not published present in the run
  filter(sample_type != "PCR_negative") %>% # remove PCR negatives
  filter(host_genus != "NoData") %>% # only use samples that have coral genus information
  mutate(host_genus = case_when(is.na(host_genus_meta) ~ host_genus, TRUE ~ host_genus_meta), # if taxonomy was not consistent between publication and symportal metadata
         host_species = case_when(is.na(host_species_meta) ~ host_species, TRUE ~ host_species_meta)) %>%
  group_by(sample_name, index) %>%
  mutate(value_rel = value/sample_sum) %>% # compute relative abundance
  filter(value_rel > filt_thresh) %>% # relative abundance filter
  ungroup()

# all as above but without relative abundance filtering
merged_clean_nofilt <- merged_data %>%
  left_join(., totals) %>%
  filter(keep == "keep") %>%
  mutate(published = case_when(is.na(published) ~ "n",
                               TRUE ~ published)) %>%
  filter(published != "n") %>% 
  filter(sample_type != "PCR_negative") %>%
  filter(host_genus != "NoData") %>%
  mutate(host_genus = case_when(is.na(host_genus_meta) ~ host_genus, TRUE ~ host_genus_meta),
         host_species = case_when(is.na(host_species_meta) ~ host_species, TRUE ~ host_species_meta)) %>%
  group_by(sample_name, index) %>%
  mutate(value_rel = value/sample_sum) %>%
  ungroup()
```

## Taxonomy cleaning

There are plenty of taxonomy spelling mistakes which prevent ease of taxon-based cleaning or analysis

```{r}
# SPELLING MISTAKES
#tubinaria
#echinophylia
#pocillipora
#montastrea
#cyhpastrea
#asteopora
#astropora
#caulastrea
#ctenastis
#echonophyllia
#physogora

# TAX REVISIONS
#favia is dipsastraea (REF)
#symphyllia is lobophyllia (REF)

# NOT GENUS
#mussidae is a family
#fungiidae was a family

# NON SCLERACTINIA
#lobophytum
#nephthea
#palythoa
#sinularia
#sarcophyton
#xenia
#millepora
#heliopora
#entacmaea

filt_nonscler <- c("lobophytum", "nephthea", "palythoa", "sinularia", "sarcophyton", "xenia", "millepora", "heliopora", "entacmaea")

merged_clean_tax <- merged_clean %>%
  mutate(host_genus = str_to_lower(host_genus)) %>%
  mutate(host_species = str_to_lower(host_species)) %>%
  mutate(host_genus = case_when(host_genus == "tubinaria" ~ "turbinaria", # spelling
                                host_genus == "cyhpastrea" ~ "cyphastrea", # spelling
                                host_genus == "asteopora" ~ "astreopora", # spelling
                                host_genus == "astropora" ~ "astreopora", # spelling
                                host_genus == "montastrea" ~ "montastraea", # spelling
                                host_genus == "caulastrea" ~ "caulastraea", # spelling 
                                host_genus == "polyhpyllia" ~ "polyphyllia", # spelling
                                host_genus == "physogora" ~ "physogyra", # spelling
                                host_genus == "ctenastis" ~ "ctenactis", # spelling
                                host_genus == "echinophylia" ~ "echinophyllia", # spelling
                                host_genus == "echonophyllia" ~ "echinophyllia", # spelling
                                host_genus == "pocillipora" ~ "pocillopora", # spelling
                                host_genus == "favia" ~ "dipsastraea", # tax revision
                                host_genus == "symphyllia" ~ "lobophyllia", # tax revision
                                TRUE ~ host_genus)) %>%
  filter(!(host_genus %in% filt_nonscler)) %>% # not scler
  filter(host_genus != "mussidae") %>% #wrong rank
  filter(host_genus != "fungiidae") #wrong rank

# unique(merged_clean_tax$host_genus)
```

## Profile data cleaning
Keep only the CD observations
```{r}
database_meta <- merged_clean_tax %>%
  distinct(index, sample_name, host_genus, host_species)

profs_clean <- full_join(merged_profs, database_meta) %>%
  filter(!is.na(host_genus))

# length(unique(profs_clean$sample_name_index)) # 6602 samples total

gen_2 <- profs_clean %>%
  filter(str_detect(name, "C|D")) %>%
  mutate(sym_genus = case_when(str_detect(name, "C") ~ "Cladocopium", TRUE ~ "Durusdinium")) %>%
  group_by(sample_name_index, sym_genus) %>%
  slice_max(value) %>%
  ungroup() %>%
  count(sample_name_index) %>%
  filter(n > 1) %>%
  pull(sample_name_index)

# length(gen_2) # 1024 samples have CD co-occurence
```

```{r}
profs_sub <- profs_clean %>%
  filter(str_detect(name, "C|D")) %>%
  filter(sample_name_index %in% gen_2) %>%
  mutate(sym_genus = case_when(str_detect(name, "C") ~ "Cladocopium", TRUE ~ "Durusdinium")) %>%
  group_by(index, sample_name_index, sym_genus) %>%
  slice_max(value) %>%
  ungroup() %>%
  filter(host_genus != "blastomussa") # n = 1 and its not in the coral tree

# length(unique(profs_sub$index)) 23 studies included in the cophylo analysis
```

## Establish symbiont trees
### C profs defined
```{r}
profs_c <- profs_sub %>%
  filter(str_detect(name, "C")) %>%
  distinct(name)

profs_defined_c <- data.frame()
for(i in 1:length(profs_c$name)){
  
  profs_temp <- profs_sub %>%
    filter(name == profs_c$name[i])
  
  div_vec <- strsplit(profs_c$name[i], "[-/ ]") %>% unlist()
  
  samp_temp <- merged_clean_nofilt %>% filter(sample_name_index %in% profs_temp$sample_name_index) %>%
    filter(name %in% div_vec) %>%
    group_by(name, sequence) %>%
    summarise(value = round(mean(value)),
              n_profs = n()) %>%
    mutate(profile = profs_c$name[i]) %>%
    ungroup()
  
  profs_defined_c <- rbind(profs_defined_c, samp_temp)
}
```

### D profs defined
```{r}
profs_d <- profs_sub %>%
  filter(str_detect(name, "D")) %>%
  distinct(name)

profs_defined_d <- data.frame()
for(i in 1:length(profs_d$name)){
  
  profs_temp <- profs_sub %>%
    filter(name == profs_d$name[i])
  
  div_vec <- strsplit(profs_d$name[i], "[-/ ]") %>% unlist()
  
  samp_temp <- merged_clean_nofilt %>% filter(sample_name_index %in% profs_temp$sample_name_index) %>%
    filter(name %in% div_vec) %>%
    group_by(name, sequence) %>%
    summarise(value = round(mean(value)),
              n_profs = n()) %>%
    mutate(profile = profs_d$name[i]) %>%
    ungroup()
  
  profs_defined_d <- rbind(profs_defined_d, samp_temp)
}
```

## Establish the combination mappings of C profile to D profile
```{r}
comb_map_wide <- profs_sub %>%
        select(sample_name_index, name) %>%
        group_by(sample_name_index) %>%
        summarise(pairs = list(combn(sort(unique(name)), 2, simplify = FALSE))) %>%
   unnest(pairs) %>%
  mutate(
    pair = sapply(pairs, function(x) paste(sort(x), collapse = "__"))
  ) %>%
  count(pair, name = "co_occurrence_count") %>%
  arrange(desc(co_occurrence_count)) %>%
  mutate(co_occurrence_count)

length(comb_map_wide$pair) # 479 unique pairs

binary_matrix <- comb_map_wide %>%
  separate(pair, into = c("c", "d"), sep = "__") %>%
  mutate(value = 1) %>% # turn this off any use next line to have a minimum count for inclusion
  mutate(value = case_when(co_occurrence_count > 1 ~ 1, TRUE ~ 0)) %>%
  filter(value > 0)

length(binary_matrix$c) # 140 unique observations

# Create a full list of unique objects
c_p <- sort(unique(binary_matrix$c))
d_p <- sort(unique(binary_matrix$d))

# Create the binary matrix
cd_cooc_matrix <- matrix(0, nrow = length(c_p), ncol = length(d_p),
                      dimnames = list(c_p, d_p))

for (i in seq_len(nrow(binary_matrix))) {
  if (binary_matrix$value[i] == 1) {
    cd_cooc_matrix[binary_matrix$c[i], binary_matrix$d[i]] <- 1
  }
}
```

### C profile unifracs
```{r}
c_2 <- binary_matrix$c

# Import and filter sequence data
fasta <- profs_defined_c %>%
  filter(profile %in% c_2) %>%
  select(name, sequence) %>%
  distinct() %>%
  deframe() %>%
  as_dna() # convert to bioseq DNA format

kdist <- fasta %>%
  dna_to_DNAbin() %>%
  kdistance(k = 8, residues = "DNA", method = "edgar") %>% # test how different k size alters the interpretation
  as.matrix()

# Use heirarchical clustering to create a phylogenetic tree based on the pairwise k-mer distances
c_tree <- kdist %>% phangorn::upgma()

c_gg_tree <- ggtree(c_tree) + geom_tiplab(aes(label = label))

# Create a wide count table to use in the weighted versions of the unifrac measurements
c_seqs_wide <- profs_defined_c %>%
  filter(profile %in% c_2) %>%
  select(profile, name, value) %>% # need the sample names, the sequence names, and the count data
  pivot_wider(names_from = name, values_from = value, values_fill = 0) %>% # convert from long to wide
  tibble::column_to_rownames(var = "profile") # sample names need to be column names

# Calculate the unifrac distance
c_unidist <- GUniFrac(c_seqs_wide, c_tree)
saveRDS(c_unidist, "c_unidst.rds")

c_unidist <- readRDS("c_unidst.rds")
c_unifracs <- c_unidist$unifracs
# c_du <- c_unifracs[, , "d_1"]		# Weighted UniFrac
# c_du <- c_unifracs[, , "d_UW"]		# Unweighted UniFrac	
# c_du <- c_unifracs[, , "d_VAW"]		# Variance adjusted weighted UniFrac
# c_du <- c_unifracs[, , "d_0"]     	# GUniFrac with alpha 0  
 c_du <- c_unifracs[, , "d_0.5"]   	# GUniFrac with alpha 0.5

# Hierarchical clustering of the samples into groups based on their pairwise unifrac distances
c_hclust_profs <- upgma(c_du)
c_profs_tree <- ggtree(c_hclust_profs) + layout_dendrogram() + theme(aspect.ratio = 0.3) + geom_tiplab()
```

### D profile unifracs
```{r}
d_2 <- binary_matrix$d

# Import and filter sequence data
fasta <- profs_defined_d %>%
  filter(profile %in% d_2) %>%
  select(name, sequence) %>%
  distinct() %>%
  deframe() %>%
  as_dna() # convert to bioseq DNA format

kdist <- fasta %>%
  dna_to_DNAbin() %>%
  kdistance(k = 8, residues = "DNA", method = "edgar") %>% # test how different k size alters the interpretation
  as.matrix()

# Use heirarchical clustering to create a phylogenetic tree based on the pairwise k-mer distances
d_tree <- kdist %>% phangorn::upgma()

d_gg_tree <- ggtree(d_tree) + geom_tiplab(aes(label = label))

# Create a wide count table to use in the weighted versions of the unifrac measurements
d_seqs_wide <- profs_defined_d %>%
      filter(profile %in% d_2) %>%
  select(profile, name, value) %>% # need the sample names, the sequence names, and the count data
  pivot_wider(names_from = name, values_from = value, values_fill = 0) %>% # convert from long to wide
  tibble::column_to_rownames(var = "profile") # sample names need to be column names

# Calculate the unifrac distance
d_unidist <- GUniFrac(d_seqs_wide, d_tree) # CAUTION!!!!! SAVED HERE TO NOT RERUN EVERYTIME
saveRDS(d_unidist, "d_unidst.rds")

d_unidist <- readRDS("d_unidst.rds")
d_unifracs <- d_unidist$unifracs
# d_du <- d_unifracs[, , "d_1"]		# Weighted UniFrac
# d_du <- d_unifracs[, , "d_UW"]		# Unweighted UniFrac	
# d_du <- d_unifracs[, , "d_VAW"]		# Variance adjusted weighted UniFrac
# d_du <- d_unifracs[, , "d_0"]     	# GUniFrac with alpha 0  
 d_du <- d_unifracs[, , "d_0.5"]   	# GUniFrac with alpha 0.5 

# Hierarchical clustering of the samples into groups based on their pairwise unifrac distances
d_hclust_profs <- upgma(d_du)
d_profs_tree <- ggtree(d_hclust_profs) + layout_dendrogram() + theme(aspect.ratio = 0.3) + geom_tiplab()
```

## Extract the distances among profiles
```{r}
c_cophen <- cophenetic(c_hclust_profs)
d_cophen <- cophenetic(d_hclust_profs)

dim(c_cophen)[1] * dim(d_cophen)[1] # = 4500 possible combinations

# scale to mean
c_cophen <- c_cophen / mean(c_cophen)
d_cophen <- d_cophen / mean(d_cophen)
```

## Perform procrustean superimposition
```{r}
cd_cophy <- prepare_paco_data(H = c_cophen, P = d_cophen, HP = cd_cooc_matrix)
cd_cophy <- add_pcoord(cd_cophy)
cd_cophy <- PACo(cd_cophy, nperm = 5000, symmetric = TRUE)
saveRDS(cd_cophy, "cd_cophy.RDS")
cd_cophy <- readRDS("cd_cophy.RDS")

cd_cophy$gof$p

ss_model <- cd_cophy$gof$ss
ss_total <- sum(cd_cophy$proc$X^2)  # total Procrustes sum of squares
R2 <- 1 - (ss_model / ss_total) # 0.25

cd_resid <- paco::residuals_paco(cd_cophy$proc, type = "interaction") %>% enframe()

# mean(resid$value) 0.05467903

resid_hist <- ggplot(cd_resid, aes(x = value, fill = ..x..)) +
                geom_histogram(bins = 15) +
                scale_fill_viridis_c(direction = -1, option = "magma") +
                theme(aspect.ratio = 0.3) +
                ylab("Count of observations") +
                xlab("Squared residuals")

resid_hist

ggsave(plot = resid_hist, filename = "resid_hist.svg", device = "svg", width = 20, height = 20/3, units = "cm")
```

# FIGURE 6

```{r}
assocmat <- cd_resid %>%
   mutate(
    split = str_split(name, "-(?=D)", n = 2),  # split into two parts
    c = map_chr(split, 1),
    d = map_chr(split, 2)
  )

cophy_tangle <- cophylo(c_hclust_profs, 
                 d_hclust_profs,
                 rotate = FALSE,
                 assoc = as.matrix(assocmat %>% select(c, d)))


viridis_pal <- colorRampPalette(rev(viridis(100, option = "magma")))
normalized_values <- scales::rescale(assocmat$value)
assocmat$palette <- viridis_pal(length(normalized_values))[rank(normalized_values)]
make.transparent <- function(col, alpha=0.5) {
  adjustcolor(col, alpha.f = alpha)
}

link_pal <- assocmat$palette
link_pal <- make.transparent(link_pal, 0.5)

# Plot the result
svg("cd_cophy_plot.svg")
cophy_plot <- plot(cophy_tangle, link.type = "curved", 
                   link.lwd = 3, 
                   link.col = link_pal, 
                   link.lty = "solid",
                   fsize = 0.4)
dev.off()
```

# PART 5: Inspecting CD:D ratio as a function of relative abundance filtering threshold

Without any relative abundance filtering, the CD:D ratio is high (~5). Because of inconsistent use of PCR controls, we cannot include all observations without any filtering. For example, if just 1 sequence in a sample belongs to Durusdinium, and 99,999 belong to Cladocopium, the presence of Durusdinium is down in the 'noise' and this observation should not likely be counted towards "CD". Can we empirically determine a filtering threshold that yields an accurate CD:D ratio?

```{r}
merged_f <- merged_clean_nofilt %>% # use the no-filt data
  mutate(host_genus = str_to_lower(host_genus)) %>% # repeat the scler taxonomy filtering steps 
  mutate(host_species = str_to_lower(host_species)) %>%
  filter(!(host_genus %in% filt_nonscler)) %>% # not scler
  filter(host_genus != "mussidae") %>% #wrong rank
  filter(host_genus != "fungiidae") %>% #wrong rank
    mutate(genus = case_when(
    str_detect(name, "A") ~ 'A',
    str_detect(name, "B") ~ 'B',
    str_detect(name, "C") ~ 'C',
    str_detect(name, "D") ~ 'D',
    str_detect(name, "E") ~ 'E',
    str_detect(name, "F") ~ 'F',
    str_detect(name, "G") ~ 'G',
    str_detect(name, "H") ~ 'H',
    str_detect(name, "I") ~ 'I',
    TRUE ~ "unknown")) %>%
  ungroup()

# Set up a sequence of 50 values between 0.001 and 0.05
filt_thresh_seq <- seq(0.001, 0.05, 0.001)
# 1] 0.001 0.002 0.003 0.004 0.005 0.006 0.007 0.008 0.009 0.010 0.011 0.012 0.013 0.014 0.015 0.016 0.017 0.018 0.019 0.020 0.021 0.022 0.023 0.024 0.025 0.026 0.027 0.028 0.029 0.030 0.031 0.032 0.033 0.034 0.035 0.036 0.037 0.038 0.039 0.040 0.041 0.042 0.043 0.044 0.045 0.046 0.047 0.048 0.049 0.050

# Loop over the data, and at each point filter out sequences below the relative abundance threshold, then re-categorise the sample (C, CD, D)
res <- data.frame()
for(i in 1:length(filt_thresh_seq)){
  temp <- merged_f %>%
  group_by(index, sample_name, host_genus, host_species) %>%
  mutate(value_rel = value/sum(value)) %>%
  filter(value_rel > filt_thresh_seq[i]) %>%
  ungroup() %>%
  group_by(index, sample_name, host_genus, host_species, genus) %>%
  summarise(value_rel = sum(value_rel)) %>%
  pivot_wider(names_from = "genus", values_from = "value_rel") %>%
  mutate(C_abundance = case_when(C > 0 ~ "P", is.na(C) ~ "A"),
         D_abundance = case_when(D > 0 ~ "P", is.na(D) ~ "A")) %>%
  ungroup() %>%
  mutate(filt_thresh = filt_thresh_seq[i])
  
  res <- rbind(res, temp)
}

ac <- res %>%
  dplyr::select(-A, -F, -B, -G) %>%
  filter(!(is.na(C) & is.na(D))) %>%
  group_by(filt_thresh) %>%
  mutate(count = case_when(C_abundance == "P" & D_abundance == "P" ~ 1, TRUE ~ 0)) %>%
  dplyr::slice(., sample(1:n())) %>%
  mutate(observations = row_number()) %>%
  mutate(colonies_with_community = cumsum(count)) %>%
  mutate(CD_r = case_when(C_abundance == "P" & D_abundance == "P" ~ 1,
                          TRUE ~ 0),
         D_r = case_when(C_abundance == "A" & D_abundance == "P" ~ 1,
                         TRUE ~ 0),
         CDr_count = CD_r + D_r
         )

# Check the ratio of CD to D with filter thresholds
ggplot(ac, aes(observations, colonies_with_community)) +
  #facet_wrap(~filt_thresh) +
  geom_smooth(method = "lm", aes(colour = filt_thresh, group = filt_thresh), size = 0.1, alpha = 0.3)

CDDr_ft <- ac %>%
  filter(CDr_count > 0) %>%
  group_by(filt_thresh) %>%
  summarise(CD_r = sum(CD_r),
            D_r = sum(D_r)) %>%
  mutate(CD_D_r = CD_r/D_r)
```

## Test a range of exponential decay models

We have an exponential decay, where too low a filtering threshold allows for excess noise, and too high a filtering threshold removes signal of CD cooccurence.

An inflection point would be a good compromise whereby we remove most noise, but don't sacrifice important observations of e.g., strong dominance, but true coexistence.

```{r}
# Simple Exponential Decay
ed <- function(a, b, x) {
 model <- a * exp(-b * x)
}

# Asymptotic Exponential Decay where d is a non-zero constant.
aed <- function(a, b, c, x) {
 model <- a * exp(-b * x) + c
}

# Double Exponential Decay
ded <- function(a, b, d, e, x) {
 model <- a * exp(-b * x) + d * exp(-e * x)
}

# Logarithmic decay where c is added to avoid log of zero
logd <- function(a, b, x, c){
  model <- a - b * log(x + c)
}


model1 <- nls.multstart::nls_multstart(CD_D_r ~ ed(a, b, x = filt_thresh),
                     data = CDDr_ft,
                     iter = 250,
                     start_lower = c(a = 1, b = 0.1),
                     start_upper = c(a = 5, b = 0.5),
                     supp_errors = 'Y',
                     convergence_count = 100,
                     na.action = na.omit,
                     lower = c(a = 1, b = 0.1))

model2 <- nls.multstart::nls_multstart(CD_D_r ~ aed(a, b, c, x = filt_thresh),
                     data = CDDr_ft,
                     iter = 250,
                     start_lower = c(a = 1, b = 0.1, c = 0.0001),
                     start_upper = c(a = 5, b = 0.5, c = 0.01),
                     supp_errors = 'Y',
                     convergence_count = 100,
                     na.action = na.omit,
                     lower = c(a = 1, b = 0.1, c = 0.0001))

model3 <- nls.multstart::nls_multstart(CD_D_r ~ ded(a, b, d, e, x = filt_thresh),
                     data = CDDr_ft,
                     iter = 250,
                     start_lower = c(a = 1, b = 0.1, d = 0.1, e = 0.01),
                     start_upper = c(a = 5, b = 0.5, d = 0.5, e = 0.1),
                     supp_errors = 'Y',
                     convergence_count = 100,
                     na.action = na.omit,
                     lower = c(a = 1, b = 0.1, d = 0.1, e = 0.01))

summary(model3)
# Formula: CD_D_r ~ ded(a, b, d, e, x = filt_thresh)
# 
# Parameters:
#    Estimate Std. Error t value Pr(>|t|)    
# a   3.82930    0.09161   41.80   <2e-16 ***
# b 409.05531   16.02526   25.53   <2e-16 ***
# d   1.48530    0.03459   42.94   <2e-16 ***
# e  24.50156    0.87809   27.90   <2e-16 ***
# ---
# Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1
# 
# Residual standard error: 0.04473 on 46 degrees of freedom
# 
# Number of iterations to convergence: 21 
# Achieved convergence tolerance: 1.49e-08

model4 <- nls.multstart::nls_multstart(CD_D_r ~ logd(a, b, c, x = filt_thresh),
                     data = CDDr_ft,
                     iter = 250,
                     start_lower = c(a = 1, b = 0.1, c = 0.0001),
                     start_upper = c(a = 5, b = 0.5, c = 0.01),
                     supp_errors = 'Y',
                     convergence_count = 100,
                     na.action = na.omit,
                     lower = c(a = 1, b = 0.1, c = 0.0001))

# Model 3 is the best - double exponential decay
aic1 <- AIC(model1)
aic2 <- AIC(model2)
aic3 <- AIC(model3)
aic4 <- AIC(model4)

cat("AIC Model 1:", aic1, "\n")
cat("AIC Model 2:", aic2, "\n")
cat("AIC Model 3:", aic3, "\n")
cat("AIC Model 4:", aic4, "\n")

# AIC Model 1: 30.9648 
# AIC Model 2: -50.37291 
# AIC Model 3: -162.9845 
# AIC Model 4: 116.0981 

# None of the classical exponential decay models fit the data perfectly, so there seem to be multiple phases.

# As a compromise, use linear breakpoint analysis to find an approximate location of each phase change.

seg <- lm(CD_D_r ~ filt_thresh, data = CDDr_ft)
model6 <- segmented(seg, seg.Z = ~ filt_thresh, 
                    #psi = list(filt_thresh = c(0.005, 0.015)),
                    npsi = 2)
summary(model6)

bps <- model6$psi[, 2]

# get the slopes manually
slopes <- coef(model6)

# first line: 
#y = b0 + b1*x
#y = intercept1 + slope1 * x

# second line:
#y = c0 + c1*x
#y = intercept2 + slope2 * x

# third line
#y = d0 + d1 *x
#y = intercept3 + slope3 * x

# At the breakpoint (break1), the segments b and c intersect

#b0 + b1*x = c0 + c1*x

b0 <- coef(model6)[[1]]
b1 <- coef(model6)[[2]]

# Important:
# the coefficients are the differences in slope in comparison to the previous slope
c1 <- coef(model6)[[2]] + coef(model6)[[3]]
break1 <- model6$psi[[3]]

#Solve for c0 (intercept of second segment):
c0 <- b0 + b1 * break1 - c1 * break1

# At the breakpoint (break2), the two lines are the same again:
# the coefficients are the differences in slope in comparison to the previous slope
d1 <- coef(model6)[[4]] + c1
break2 <- model6$psi[[4]]

#Solve for d0 (intercept of third segment):
d0 <- c0 + c1 * break2 - d1 * break2

# 	***Regression Model with Segmented Relationship(s)***
# 
# Call: 
# segmented.lm(obj = seg, seg.Z = ~filt_thresh, npsi = 2)
# 
# Estimated Break-Point(s):
#                    Est. St.Err
# psi1.filt_thresh 0.004  0.000
# psi2.filt_thresh 0.016  0.001
# 
# Coefficients of the linear terms:
#                  Estimate Std. Error t value Pr(>|t|)    
# (Intercept)       4.52536    0.08093   55.92   <2e-16 ***
# filt_thresh    -649.68946   29.55039  -21.99   <2e-16 ***
# U1.filt_thresh  578.91884   30.06257   19.26       NA    
# U2.filt_thresh   57.75836    5.64505   10.23       NA    
# ---
# Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1
# 
# Residual standard error: 0.06608 on 44 degrees of freedom
# Multiple R-Squared: 0.9916,  Adjusted R-squared: 0.9907 
# 
# Boot restarting based on 8 samples. Last fit:
# Convergence attained in 2 iterations (rel. change 4.1492e-11)

# Create a new data frame for predictions
predictions <- data.frame(
  filt_thresh = seq(min(CDDr_ft$filt_thresh), max(CDDr_ft$filt_thresh), length.out = 100)
)

# Predictions from each model
predictions <- predictions %>%
  mutate(
    #model1 = predict(model1, newdata = predictions),
    #model2 = predict(model2, newdata = predictions),
    model3 = predict(model3, newdata = predictions),
    #model5 = predict(model5, newdata = predictions),
    model6 = predict(model6, newdata = predictions)
  )

# center point between the two breakpoints = 0.01
center <- bps[1] + ((bps[2] - bps[1])/2)
```

# Figure S1

```{r}
figure_s1 <- ggplot(CDDr_ft, aes(filt_thresh, CD_D_r)) +
  geom_hline(yintercept = 1, colour = "grey80", size = 2, alpha = 0.3) +
  #geom_line(aes(x = filt_thresh, y = model3), color = "blue", data = predictions) +
  #geom_line(aes(x = filt_thresh, y = model6), color = "red", data = predictions) +
  geom_abline(intercept = b0, slope = b1, colour = "deepskyblue", size = 1.5) +
  geom_abline(intercept = d0, slope = d1, colour = "coral", size = 1.5) +
  geom_vline(xintercept = bps, linetype = "dashed", size = 0.8, colour = c("deepskyblue","coral")) +
  geom_vline(xintercept = center, size = 0.8, linetype = "dashed") +
  geom_point(size = 2) +
  scale_x_continuous(breaks = seq(0, 0.1, by = 0.01)) +
  scale_y_continuous(breaks = seq(0, 5, by = 0.2)) +
  theme(aspect.ratio = 0.5) +
  theme_bw() +
  xlab("Filtering threshold (proportion)") +
  ylab("Ratio of CD to D")

ggsave("figure_s1.svg", figure_s1, width=10, height=6)
```
